{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "committed-atmosphere",
   "metadata": {},
   "source": [
    "#  Maleware Classification using bytes files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "flush-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quick-exploration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>00</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>f9</th>\n",
       "      <th>fa</th>\n",
       "      <th>fb</th>\n",
       "      <th>fc</th>\n",
       "      <th>fd</th>\n",
       "      <th>fe</th>\n",
       "      <th>ff</th>\n",
       "      <th>??</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01azqd4InC7m9JpocGv5</td>\n",
       "      <td>601905</td>\n",
       "      <td>3905</td>\n",
       "      <td>2816</td>\n",
       "      <td>3832</td>\n",
       "      <td>3345</td>\n",
       "      <td>3242</td>\n",
       "      <td>3650</td>\n",
       "      <td>3201</td>\n",
       "      <td>2965</td>\n",
       "      <td>...</td>\n",
       "      <td>3101</td>\n",
       "      <td>3211</td>\n",
       "      <td>3097</td>\n",
       "      <td>2758</td>\n",
       "      <td>3099</td>\n",
       "      <td>2759</td>\n",
       "      <td>5753</td>\n",
       "      <td>1824</td>\n",
       "      <td>5256192</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01IsoiSMh5gxyDYTl4CB</td>\n",
       "      <td>39755</td>\n",
       "      <td>8337</td>\n",
       "      <td>7249</td>\n",
       "      <td>7186</td>\n",
       "      <td>8663</td>\n",
       "      <td>6844</td>\n",
       "      <td>8420</td>\n",
       "      <td>7589</td>\n",
       "      <td>9291</td>\n",
       "      <td>...</td>\n",
       "      <td>439</td>\n",
       "      <td>281</td>\n",
       "      <td>302</td>\n",
       "      <td>7639</td>\n",
       "      <td>518</td>\n",
       "      <td>17001</td>\n",
       "      <td>54902</td>\n",
       "      <td>8588</td>\n",
       "      <td>6874624</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01jsnpXSAlgw6aPeDxrU</td>\n",
       "      <td>93506</td>\n",
       "      <td>9542</td>\n",
       "      <td>2568</td>\n",
       "      <td>2438</td>\n",
       "      <td>8925</td>\n",
       "      <td>9330</td>\n",
       "      <td>9007</td>\n",
       "      <td>2342</td>\n",
       "      <td>9107</td>\n",
       "      <td>...</td>\n",
       "      <td>2242</td>\n",
       "      <td>2885</td>\n",
       "      <td>2863</td>\n",
       "      <td>2471</td>\n",
       "      <td>2786</td>\n",
       "      <td>2680</td>\n",
       "      <td>49144</td>\n",
       "      <td>468</td>\n",
       "      <td>4825600</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01kcPWA9K2BOxQeS5Rju</td>\n",
       "      <td>21091</td>\n",
       "      <td>1213</td>\n",
       "      <td>726</td>\n",
       "      <td>817</td>\n",
       "      <td>1257</td>\n",
       "      <td>625</td>\n",
       "      <td>550</td>\n",
       "      <td>523</td>\n",
       "      <td>1078</td>\n",
       "      <td>...</td>\n",
       "      <td>485</td>\n",
       "      <td>462</td>\n",
       "      <td>516</td>\n",
       "      <td>1133</td>\n",
       "      <td>471</td>\n",
       "      <td>761</td>\n",
       "      <td>7998</td>\n",
       "      <td>13940</td>\n",
       "      <td>712704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01SuzwMJEIXsK7A8dQbl</td>\n",
       "      <td>19764</td>\n",
       "      <td>710</td>\n",
       "      <td>302</td>\n",
       "      <td>433</td>\n",
       "      <td>559</td>\n",
       "      <td>410</td>\n",
       "      <td>262</td>\n",
       "      <td>249</td>\n",
       "      <td>422</td>\n",
       "      <td>...</td>\n",
       "      <td>350</td>\n",
       "      <td>209</td>\n",
       "      <td>239</td>\n",
       "      <td>653</td>\n",
       "      <td>221</td>\n",
       "      <td>242</td>\n",
       "      <td>2199</td>\n",
       "      <td>9008</td>\n",
       "      <td>460288</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID      00    01    02    03    04    05    06    07  \\\n",
       "0  01azqd4InC7m9JpocGv5  601905  3905  2816  3832  3345  3242  3650  3201   \n",
       "1  01IsoiSMh5gxyDYTl4CB   39755  8337  7249  7186  8663  6844  8420  7589   \n",
       "2  01jsnpXSAlgw6aPeDxrU   93506  9542  2568  2438  8925  9330  9007  2342   \n",
       "3  01kcPWA9K2BOxQeS5Rju   21091  1213   726   817  1257   625   550   523   \n",
       "4  01SuzwMJEIXsK7A8dQbl   19764   710   302   433   559   410   262   249   \n",
       "\n",
       "     08  ...    f9    fa    fb    fc    fd     fe     ff     ??  size_bytes  \\\n",
       "0  2965  ...  3101  3211  3097  2758  3099   2759   5753   1824     5256192   \n",
       "1  9291  ...   439   281   302  7639   518  17001  54902   8588     6874624   \n",
       "2  9107  ...  2242  2885  2863  2471  2786   2680  49144    468     4825600   \n",
       "3  1078  ...   485   462   516  1133   471    761   7998  13940      712704   \n",
       "4   422  ...   350   209   239   653   221    242   2199   9008      460288   \n",
       "\n",
       "   Class  \n",
       "0      9  \n",
       "1      2  \n",
       "2      9  \n",
       "3      1  \n",
       "4      8  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bytes = pd.read_csv('C:\\\\Users\\\\Vipul Singh\\\\Desktop\\\\train (1)\\\\Bytes.csv')\n",
    "df_bytes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prerequisite-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_bytes['Class']\n",
    "X = df_bytes.drop(['ID', 'Class'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "under-sharp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class distribution of data\n",
    "ax = sns.countplot(x = 'Class', data = df_bytes)\n",
    "\n",
    "for c, p in enumerate(ax.patches):\n",
    "    ax.annotate('{:.1f}%'.format(100*p.get_height()/len(df_bytes)), (p.get_x()+0.1, p.get_height()+5))   \n",
    "\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-enclosure",
   "metadata": {},
   "source": [
    "Data for Class 5, 4, 7 is very less.<br>\n",
    "Data for Class 3, 2, 1 is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-incidence",
   "metadata": {},
   "source": [
    "### Analysis of size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "handled-portfolio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data = df_bytes, x = 'Class', y = 'size_bytes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recovered-planet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='size_bytes'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot( x = df_bytes.index, y = df_bytes.size_bytes,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-genesis",
   "metadata": {},
   "source": [
    "## Split train Val and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "false-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-prairie",
   "metadata": {},
   "source": [
    "## Model using bytes files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-reynolds",
   "metadata": {},
   "source": [
    "### 1. XgBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "raising-lighting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:14:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:14:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:15:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:15:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:15:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Train error for xgboost is  0.0009244922284258935\n",
      "Cross Validation error for xgboost is  0.04310740307429337\n",
      "Train error for xgboost with calliberation is  0.022440167956136396\n",
      "Cross Validation error for xgboost with calliberation is  0.06557363734188314\n"
     ]
    }
   ],
   "source": [
    "# xgboost model\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# calliberartion model\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", )\n",
    "sig_clf.fit(x_train, y_train)\n",
    "\n",
    "# find log loss error\n",
    "loss = log_loss(y_val, clf.predict_proba(x_val) )\n",
    "\n",
    "loss_c = log_loss(y_val, sig_clf.predict_proba(x_val) )\n",
    "\n",
    "print('Train error for xgboost is ', log_loss(y_train, clf.predict_proba(x_train)))\n",
    "print('Cross Validation error for xgboost is ',loss)\n",
    "\n",
    "print('Train error for xgboost with calliberation is ', log_loss(y_train, sig_clf.predict_proba(x_train)))\n",
    "print('Cross Validation error for xgboost with calliberation is ',loss_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-income",
   "metadata": {},
   "source": [
    "### 2. LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "considerable-smile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for LightGBM Classifier is  2.603933895557233e-06\n",
      "Cross Validation error for LightGBM Classifier is  0.05293871465955139\n",
      "Train error for LightGBM Classifier with calliberation is  0.02117173045354391\n",
      "Cross Validation error for LightGBM Classifier with calliberation is  0.06069275661383898\n"
     ]
    }
   ],
   "source": [
    "# LightGBM model\n",
    "clf = LGBMClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# calliberartion model\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", )\n",
    "sig_clf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# find log loss error\n",
    "loss = log_loss(y_val, clf.predict_proba(x_val))\n",
    "loss_c = log_loss(y_val, sig_clf.predict_proba(x_val))\n",
    "\n",
    "print('Train error for LightGBM Classifier is ', log_loss(y_train, clf.predict_proba(x_train)))\n",
    "print('Cross Validation error for LightGBM Classifier is ',loss)\n",
    "\n",
    "print('Train error for LightGBM Classifier with calliberation is ', log_loss(y_train, sig_clf.predict_proba(x_train)))\n",
    "print('Cross Validation error for LightGBM Classifier with calliberation is ',loss_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-philosophy",
   "metadata": {},
   "source": [
    "### 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "soviet-feeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for Random Forest Classifier is  0.027537508369056378\n",
      "Cross Validation error for Random Forest Classifier is  0.09967721792286391\n",
      "Train error for Random Forest Classifier with calliberation is  0.02558939515088649\n",
      "Cross Validation error for Random Forest Classifier with calliberation is  0.06750238635683\n"
     ]
    }
   ],
   "source": [
    "# RandomForest model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# calliberartion model\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", )\n",
    "sig_clf.fit(x_train, y_train)\n",
    "\n",
    "# predict probability\n",
    "y_probs = sig_clf.predict_proba(x_val)\n",
    "\n",
    "# find log loss error\n",
    "loss = log_loss(y_val, clf.predict_proba(x_val))\n",
    "loss_c = log_loss(y_val, sig_clf.predict_proba(x_val))\n",
    "\n",
    "print('Train error for Random Forest Classifier is ', log_loss(y_train, clf.predict_proba(x_train)))\n",
    "print('Cross Validation error for Random Forest Classifier is ',loss)\n",
    "\n",
    "print('Train error for Random Forest Classifier with calliberation is ', log_loss(y_train, sig_clf.predict_proba(x_train)))\n",
    "print('Cross Validation error for Random Forest Classifier with calliberation is ',loss_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-pocket",
   "metadata": {},
   "source": [
    "### 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "parliamentary-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "s = StandardScaler()\n",
    "\n",
    "x_train_s = s.fit_transform(X = x_train)\n",
    "x_val_s = s.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adapted-detroit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for LogisticRegression is  2.196120061240388\n",
      "Cross Validation error for LogisticRegression is  2.1961130345094033\n",
      "Train error for LogisticRegression with calliberation is  0.9906380382153519\n",
      "Cross Validation error for LogisticRegression with calliberation is  1.0019339185504255\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "clf = LogisticRegression(penalty='l2',class_weight='balanced', max_iter = 1500)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# calliberartion model\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", )\n",
    "sig_clf.fit(x_train_s, y_train)\n",
    "\n",
    "# predict probability\n",
    "y_probs = clf.predict_proba(x_val_s)\n",
    "\n",
    "# find log loss error\n",
    "loss = log_loss(y_val, clf.predict_proba(x_val_s))\n",
    "loss_c = log_loss(y_val, sig_clf.predict_proba(x_val_s))\n",
    "\n",
    "print('Train error for LogisticRegression is ', log_loss(y_train, clf.predict_proba(x_train_s)))\n",
    "print('Cross Validation error for LogisticRegression is ',loss)\n",
    "\n",
    "print('Train error for LogisticRegression with calliberation is ', log_loss(y_train, sig_clf.predict_proba(x_train_s)))\n",
    "print('Cross Validation error for LogisticRegression with calliberation is ',loss_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-monkey",
   "metadata": {},
   "source": [
    "### 5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "local-apache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for Decision Tree Classifier is  8.104628079763677e-15\n",
      "Cross Validation error for Decision Tree Classifier is  1.408665213285234\n",
      "Train error for Decision Tree Classifier with calliberation is  0.0629306299093547\n",
      "Cross Validation error for Decision Tree Classifier with calliberation is  0.14412437244507287\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree model\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# calliberartion model\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", )\n",
    "sig_clf.fit(x_train, y_train)\n",
    "\n",
    "# predict probability\n",
    "y_probs = sig_clf.predict_proba(x_val)\n",
    "\n",
    "# find log loss error\n",
    "loss = log_loss(y_val, clf.predict_proba(x_val))\n",
    "loss_c = log_loss(y_val, sig_clf.predict_proba(x_val))\n",
    "\n",
    "print('Train error for Decision Tree Classifier is ', log_loss(y_train, clf.predict_proba(x_train)))\n",
    "print('Cross Validation error for Decision Tree Classifier is ',loss)\n",
    "\n",
    "print('Train error for Decision Tree Classifier with calliberation is ', log_loss(y_train, sig_clf.predict_proba(x_train)))\n",
    "print('Cross Validation error for Decision Tree Classifier with calliberation is ',loss_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-difference",
   "metadata": {},
   "source": [
    "### 6. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "better-consolidation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for GaussianNB is  30.606795277782705\n",
      "Cross Validation error for GaussianNB is  30.70466506251031\n",
      "Train error for GaussianNB with calliberation is  1.1256327425129629\n",
      "Cross Validation error for GaussianNB with calliberation is  1.1178911154655091\n"
     ]
    }
   ],
   "source": [
    "# GaussianNB model\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# calliberartion model\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", )\n",
    "sig_clf.fit(x_train_s, y_train)\n",
    "\n",
    "# predict probability\n",
    "y_probs = clf.predict_proba(x_val_s)\n",
    "\n",
    "# find log loss error\n",
    "loss = log_loss(y_val, clf.predict_proba(x_val_s))\n",
    "loss_c = log_loss(y_val, sig_clf.predict_proba(x_val_s))\n",
    "\n",
    "print('Train error for GaussianNB is ', log_loss(y_train, clf.predict_proba(x_train_s)))\n",
    "print('Cross Validation error for GaussianNB is ',loss)\n",
    "\n",
    "print('Train error for GaussianNB with calliberation is ', log_loss(y_train, sig_clf.predict_proba(x_train_s)))\n",
    "print('Cross Validation error for GaussianNB with calliberation is ',loss_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-background",
   "metadata": {},
   "source": [
    "### 7. Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "coastal-subcommittee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for SVC is  3.119091667469305\n",
      "Cross Validation error for SVC is  3.1043952594181463\n",
      "Train error for SVC with calliberation is  0.734782261706861\n",
      "Cross Validation error for SVC with calliberation is  0.7401606624647641\n"
     ]
    }
   ],
   "source": [
    "# Support vector model\n",
    "clf = SVC(probability = True)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# calliberartion model\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", )\n",
    "sig_clf.fit(x_train_s, y_train)\n",
    "\n",
    "# predict probability\n",
    "y_probs = clf.predict_proba(x_val_s)\n",
    "\n",
    "# find log loss error\n",
    "loss = log_loss(y_val, clf.predict_proba(x_val_s))\n",
    "loss_c = log_loss(y_val, sig_clf.predict_proba(x_val_s))\n",
    "\n",
    "print('Train error for SVC is ', log_loss(y_train, clf.predict_proba(x_train_s)))\n",
    "print('Cross Validation error for SVC is ',loss)\n",
    "\n",
    "print('Train error for SVC with calliberation is ', log_loss(y_train, sig_clf.predict_proba(x_train_s)))\n",
    "print('Cross Validation error for SVC with calliberation is ',loss_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-retail",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning for xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fitting-collector",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:40:09,145]\u001b[0m A new study created in memory with name: no-name-f537170a-e59b-42c9-b87b-c466c3a64e71\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:40:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { gamma, max_depth } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:40:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:40:30,570]\u001b[0m Trial 0 finished with value: 0.6485651143907455 and parameters: {'booster': 'gblinear', 'learning_rate': 0.015636275457700768, 'n_estimators': 500, 'max_depth': 4, 'gamma': 0.006414226519250831}. Best is trial 0 with value: 0.6485651143907455.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:40:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:41:22,921]\u001b[0m Trial 1 finished with value: 1.3331314532239902 and parameters: {'booster': 'gbtree', 'learning_rate': 0.0019863393430575855, 'n_estimators': 200, 'max_depth': 3, 'gamma': 0.41239995159826043}. Best is trial 0 with value: 0.6485651143907455.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { gamma, max_depth } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:41:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:41:27,128]\u001b[0m Trial 2 finished with value: 0.8019077161402229 and parameters: {'booster': 'gblinear', 'learning_rate': 0.17051629815748606, 'n_estimators': 100, 'max_depth': 6, 'gamma': 0.013052880227972807}. Best is trial 0 with value: 0.6485651143907455.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:41:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { gamma, max_depth } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:41:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:41:48,287]\u001b[0m Trial 3 finished with value: 0.8768460679705092 and parameters: {'booster': 'gblinear', 'learning_rate': 0.0021562803733439764, 'n_estimators': 500, 'max_depth': 5, 'gamma': 0.738739251827134}. Best is trial 0 with value: 0.6485651143907455.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:41:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:44:40,340]\u001b[0m Trial 4 finished with value: 1.038813821763504 and parameters: {'booster': 'gbtree', 'learning_rate': 0.0012055642057660573, 'n_estimators': 500, 'max_depth': 4, 'gamma': 0.019846101075192715}. Best is trial 0 with value: 0.6485651143907455.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:44:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { gamma, max_depth } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:44:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:44:53,468]\u001b[0m Trial 5 finished with value: 0.919993555964058 and parameters: {'booster': 'gblinear', 'learning_rate': 0.002945927635952226, 'n_estimators': 300, 'max_depth': 6, 'gamma': 0.3802690946836468}. Best is trial 0 with value: 0.6485651143907455.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:44:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { gamma, max_depth } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:44:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:45:00,329]\u001b[0m Trial 6 finished with value: 0.6404720658966232 and parameters: {'booster': 'gblinear', 'learning_rate': 0.04642161134038192, 'n_estimators': 150, 'max_depth': 5, 'gamma': 0.003469953779551092}. Best is trial 6 with value: 0.6404720658966232.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:45:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:45:38,457]\u001b[0m Trial 7 finished with value: 0.0664705074375409 and parameters: {'booster': 'gbtree', 'learning_rate': 0.0558694516037285, 'n_estimators': 150, 'max_depth': 3, 'gamma': 0.001055263910321785}. Best is trial 7 with value: 0.0664705074375409.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:45:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:46:57,843]\u001b[0m Trial 8 finished with value: 0.21795828763152222 and parameters: {'booster': 'gbtree', 'learning_rate': 0.01039555008143208, 'n_estimators': 300, 'max_depth': 3, 'gamma': 0.08131093714177984}. Best is trial 7 with value: 0.0664705074375409.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:46:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:49:01,350]\u001b[0m Trial 9 finished with value: 0.04663604803431937 and parameters: {'booster': 'gbtree', 'learning_rate': 0.21262194145608326, 'n_estimators': 500, 'max_depth': 4, 'gamma': 0.49425486815407904}. Best is trial 9 with value: 0.04663604803431937.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:49:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:50:55,938]\u001b[0m Trial 10 finished with value: 0.045291072580321515 and parameters: {'booster': 'gbtree', 'learning_rate': 0.4464050722620549, 'n_estimators': 600, 'max_depth': 7, 'gamma': 0.0976173615955861}. Best is trial 10 with value: 0.045291072580321515.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:50:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 11:56:11,846]\u001b[0m Trial 11 finished with value: 0.0513325360470267 and parameters: {'booster': 'gbtree', 'learning_rate': 0.655873934403306, 'n_estimators': 600, 'max_depth': 7, 'gamma': 0.13664556285714363}. Best is trial 10 with value: 0.045291072580321515.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:56:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:01:06,100]\u001b[0m Trial 12 finished with value: 0.046628485085597936 and parameters: {'booster': 'gbtree', 'learning_rate': 0.5680376594934557, 'n_estimators': 600, 'max_depth': 7, 'gamma': 0.08459477515967029}. Best is trial 10 with value: 0.045291072580321515.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:01:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:05:07,173]\u001b[0m Trial 13 finished with value: 0.0520813505196306 and parameters: {'booster': 'gbtree', 'learning_rate': 0.7414263569253497, 'n_estimators': 600, 'max_depth': 7, 'gamma': 0.06396766342281245}. Best is trial 10 with value: 0.045291072580321515.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:05:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:11:44,106]\u001b[0m Trial 14 finished with value: 0.04608987828172258 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2753067145711259, 'n_estimators': 600, 'max_depth': 7, 'gamma': 0.1593061973937175}. Best is trial 10 with value: 0.045291072580321515.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:11:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:13:55,314]\u001b[0m Trial 15 finished with value: 0.04505941562896533 and parameters: {'booster': 'gbtree', 'learning_rate': 0.21699059586201142, 'n_estimators': 180, 'max_depth': 7, 'gamma': 0.14739282434832937}. Best is trial 15 with value: 0.04505941562896533.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:16:37,831]\u001b[0m Trial 16 finished with value: 0.04318460671722676 and parameters: {'booster': 'gbtree', 'learning_rate': 0.09057455208180132, 'n_estimators': 180, 'max_depth': 7, 'gamma': 0.03517581804412198}. Best is trial 16 with value: 0.04318460671722676.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:16:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:19:16,468]\u001b[0m Trial 17 finished with value: 0.04286619464300707 and parameters: {'booster': 'gbtree', 'learning_rate': 0.10596474306533403, 'n_estimators': 180, 'max_depth': 7, 'gamma': 0.040770684988275546}. Best is trial 17 with value: 0.04286619464300707.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:22:26,594]\u001b[0m Trial 18 finished with value: 0.042911460277694415 and parameters: {'booster': 'gbtree', 'learning_rate': 0.07747532803424721, 'n_estimators': 180, 'max_depth': 7, 'gamma': 0.025772017642768517}. Best is trial 17 with value: 0.04286619464300707.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:22:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:27:23,735]\u001b[0m Trial 19 finished with value: 0.08390636668660201 and parameters: {'booster': 'gbtree', 'learning_rate': 0.02333640894148352, 'n_estimators': 180, 'max_depth': 7, 'gamma': 0.007140398656247103}. Best is trial 17 with value: 0.04286619464300707.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:27:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:30:24,265]\u001b[0m Trial 20 finished with value: 0.04457656254839132 and parameters: {'booster': 'gbtree', 'learning_rate': 0.09717365763609923, 'n_estimators': 180, 'max_depth': 6, 'gamma': 0.03860074115559658}. Best is trial 17 with value: 0.04286619464300707.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:30:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:34:04,698]\u001b[0m Trial 21 finished with value: 0.042976429122488606 and parameters: {'booster': 'gbtree', 'learning_rate': 0.07337467550049534, 'n_estimators': 180, 'max_depth': 7, 'gamma': 0.03153346233619234}. Best is trial 17 with value: 0.04286619464300707.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:34:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:37:15,604]\u001b[0m Trial 22 finished with value: 0.042889300222901286 and parameters: {'booster': 'gbtree', 'learning_rate': 0.09321569389095374, 'n_estimators': 180, 'max_depth': 7, 'gamma': 0.019163196778688548}. Best is trial 17 with value: 0.04286619464300707.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:37:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:42:21,154]\u001b[0m Trial 23 finished with value: 0.05655508708352739 and parameters: {'booster': 'gbtree', 'learning_rate': 0.03319975142129349, 'n_estimators': 180, 'max_depth': 7, 'gamma': 0.013750464951674077}. Best is trial 17 with value: 0.04286619464300707.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:42:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:45:08,417]\u001b[0m Trial 24 finished with value: 0.04212796949823317 and parameters: {'booster': 'gbtree', 'learning_rate': 0.11733826509329463, 'n_estimators': 180, 'max_depth': 7, 'gamma': 0.004731024883404782}. Best is trial 24 with value: 0.04212796949823317.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:45:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:47:53,002]\u001b[0m Trial 25 finished with value: 0.04378596780519572 and parameters: {'booster': 'gbtree', 'learning_rate': 0.12419700956845155, 'n_estimators': 200, 'max_depth': 5, 'gamma': 0.0026966223932147616}. Best is trial 24 with value: 0.04212796949823317.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:47:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:49:17,670]\u001b[0m Trial 26 finished with value: 0.04079843337222174 and parameters: {'booster': 'gbtree', 'learning_rate': 0.3801293057766122, 'n_estimators': 180, 'max_depth': 7, 'gamma': 0.0017507946108911408}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:49:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:50:20,546]\u001b[0m Trial 27 finished with value: 0.04267497140996228 and parameters: {'booster': 'gbtree', 'learning_rate': 0.3989789502569408, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.00105049206120728}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:50:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:51:26,378]\u001b[0m Trial 28 finished with value: 0.04155748471388354 and parameters: {'booster': 'gbtree', 'learning_rate': 0.37104801785025987, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.0010249432107403782}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { gamma, max_depth } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:51:40,751]\u001b[0m Trial 29 finished with value: 1.0227026880510073 and parameters: {'booster': 'gblinear', 'learning_rate': 0.28167716599022374, 'n_estimators': 100, 'max_depth': 4, 'gamma': 0.001794816945903727}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:52:46,391]\u001b[0m Trial 30 finished with value: 0.0428690226392172 and parameters: {'booster': 'gbtree', 'learning_rate': 0.3714350290717982, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.0061127186222751945}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:52:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:53:48,464]\u001b[0m Trial 31 finished with value: 0.04300219524989379 and parameters: {'booster': 'gbtree', 'learning_rate': 0.41174231968840475, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.001050339815214877}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:53:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:54:32,029]\u001b[0m Trial 32 finished with value: 0.04768111083585949 and parameters: {'booster': 'gbtree', 'learning_rate': 0.7420566633013944, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.0016407868026492058}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:54:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:55:51,677]\u001b[0m Trial 33 finished with value: 0.04321295371795439 and parameters: {'booster': 'gbtree', 'learning_rate': 0.1653182385794156, 'n_estimators': 100, 'max_depth': 3, 'gamma': 0.0016737153274534158}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:55:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:57:02,265]\u001b[0m Trial 34 finished with value: 0.04159016713470602 and parameters: {'booster': 'gbtree', 'learning_rate': 0.3294166885788087, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.003940508035017681}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:57:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:59:28,777]\u001b[0m Trial 35 finished with value: 0.04103491688152263 and parameters: {'booster': 'gbtree', 'learning_rate': 0.15624129377960727, 'n_estimators': 200, 'max_depth': 7, 'gamma': 0.004684809328024124}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:59:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { gamma, max_depth } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:59:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 12:59:56,980]\u001b[0m Trial 36 finished with value: 0.7472672573948754 and parameters: {'booster': 'gblinear', 'learning_rate': 0.009998851701926546, 'n_estimators': 200, 'max_depth': 6, 'gamma': 0.009080373236015755}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:59:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:02:16,708]\u001b[0m Trial 37 finished with value: 0.04254619788626261 and parameters: {'booster': 'gbtree', 'learning_rate': 0.16124327311739964, 'n_estimators': 200, 'max_depth': 5, 'gamma': 0.0029193966661395154}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:02:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { gamma, max_depth } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:02:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:02:44,851]\u001b[0m Trial 38 finished with value: 1.264131803499338 and parameters: {'booster': 'gblinear', 'learning_rate': 0.27135214467955027, 'n_estimators': 200, 'max_depth': 4, 'gamma': 0.002013913108742783}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:02:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:03:38,674]\u001b[0m Trial 39 finished with value: 0.041336710518002966 and parameters: {'booster': 'gbtree', 'learning_rate': 0.5201192091536763, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.0047361755349173635}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:03:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:05:19,896]\u001b[0m Trial 40 finished with value: 0.0457259393339573 and parameters: {'booster': 'gbtree', 'learning_rate': 0.5240078782685441, 'n_estimators': 300, 'max_depth': 3, 'gamma': 0.010055048469712422}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:05:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:06:01,787]\u001b[0m Trial 41 finished with value: 0.045833406209287456 and parameters: {'booster': 'gbtree', 'learning_rate': 0.786685111110006, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.004221230523520968}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:06:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:07:11,471]\u001b[0m Trial 42 finished with value: 0.04351302411872318 and parameters: {'booster': 'gbtree', 'learning_rate': 0.33531004220516153, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.0025140610175225222}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:07:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:08:44,834]\u001b[0m Trial 43 finished with value: 0.04251872937960141 and parameters: {'booster': 'gbtree', 'learning_rate': 0.20762663751806437, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.0013880946426820515}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:08:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:11:08,352]\u001b[0m Trial 44 finished with value: 0.04224004150506526 and parameters: {'booster': 'gbtree', 'learning_rate': 0.556901954972033, 'n_estimators': 500, 'max_depth': 6, 'gamma': 0.0041962836835707186}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:11:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:13:13,805]\u001b[0m Trial 45 finished with value: 0.04267724105645659 and parameters: {'booster': 'gbtree', 'learning_rate': 0.16324765508811587, 'n_estimators': 150, 'max_depth': 7, 'gamma': 0.0056096051576460535}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:13:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:14:09,054]\u001b[0m Trial 46 finished with value: 0.04231270501706796 and parameters: {'booster': 'gbtree', 'learning_rate': 0.4837976360748889, 'n_estimators': 100, 'max_depth': 5, 'gamma': 0.003474382402898186}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:14:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { gamma, max_depth } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:14:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:14:37,404]\u001b[0m Trial 47 finished with value: 1.2278243080191575 and parameters: {'booster': 'gblinear', 'learning_rate': 0.24450670357996185, 'n_estimators': 200, 'max_depth': 7, 'gamma': 0.0012721110236513778}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:14:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:15:48,748]\u001b[0m Trial 48 finished with value: 0.0438616873527397 and parameters: {'booster': 'gbtree', 'learning_rate': 0.31984357652959006, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.0082899375937415}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:15:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:16:49,871]\u001b[0m Trial 49 finished with value: 0.045485394135864735 and parameters: {'booster': 'gbtree', 'learning_rate': 0.7502203452572338, 'n_estimators': 150, 'max_depth': 4, 'gamma': 0.013393707167582584}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:25:39,518]\u001b[0m Trial 50 finished with value: 0.32550478910091135 and parameters: {'booster': 'gbtree', 'learning_rate': 0.006220700594548817, 'n_estimators': 300, 'max_depth': 7, 'gamma': 0.0022492608052885566}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:25:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:29:36,650]\u001b[0m Trial 51 finished with value: 0.04180285669749812 and parameters: {'booster': 'gbtree', 'learning_rate': 0.13395697172131607, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.0052395679516951815}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:33:08,553]\u001b[0m Trial 52 finished with value: 0.04175998311523033 and parameters: {'booster': 'gbtree', 'learning_rate': 0.13758925816390866, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.003468369713859344}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:33:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:36:03,992]\u001b[0m Trial 53 finished with value: 0.043319454547832495 and parameters: {'booster': 'gbtree', 'learning_rate': 0.20740105355054203, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.003274002549006825}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:36:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:38:08,601]\u001b[0m Trial 54 finished with value: 0.04578663690621159 and parameters: {'booster': 'gbtree', 'learning_rate': 0.6036465871280368, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.0037015391783450213}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:38:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:44:32,305]\u001b[0m Trial 55 finished with value: 0.0423882406512429 and parameters: {'booster': 'gbtree', 'learning_rate': 0.05208449979734435, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.001283055271601784}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:44:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:45:22,173]\u001b[0m Trial 56 finished with value: 0.043957567173917626 and parameters: {'booster': 'gbtree', 'learning_rate': 0.42813755232704787, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.0022889736539705163}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:47:55,302]\u001b[0m Trial 57 finished with value: 0.07124871250271411 and parameters: {'booster': 'gbtree', 'learning_rate': 0.03880593031923173, 'n_estimators': 200, 'max_depth': 3, 'gamma': 0.007505676544262659}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:50:07,110]\u001b[0m Trial 58 finished with value: 0.049241494858975596 and parameters: {'booster': 'gbtree', 'learning_rate': 0.07407538756930708, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.010633375741113038}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:50:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:52:53,532]\u001b[0m Trial 59 finished with value: 0.04373452942072188 and parameters: {'booster': 'gbtree', 'learning_rate': 0.33530979430293556, 'n_estimators': 600, 'max_depth': 7, 'gamma': 0.006496512278198829}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:56:05,115]\u001b[0m Trial 60 finished with value: 0.042521575927827265 and parameters: {'booster': 'gbtree', 'learning_rate': 0.19886605114699005, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.017840571638164472}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:56:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 13:59:39,823]\u001b[0m Trial 61 finished with value: 0.04198623804608816 and parameters: {'booster': 'gbtree', 'learning_rate': 0.1363812340970548, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.005073129497440681}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:04:51,419]\u001b[0m Trial 62 finished with value: 0.04222385715657268 and parameters: {'booster': 'gbtree', 'learning_rate': 0.05984573770773578, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.0048993611967664535}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:07:29,555]\u001b[0m Trial 63 finished with value: 0.04083579025327488 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2535931631269643, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.0029801957379253217}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:07:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:09:45,203]\u001b[0m Trial 64 finished with value: 0.042026663761780214 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2886193548551585, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.0032934573628682477}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:09:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:10:53,716]\u001b[0m Trial 65 finished with value: 0.04275892118776332 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2347588192098174, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.0025468706796427684}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:11:56,796]\u001b[0m Trial 66 finished with value: 0.04466593402192863 and parameters: {'booster': 'gbtree', 'learning_rate': 0.47582620841215784, 'n_estimators': 200, 'max_depth': 6, 'gamma': 0.001539150784862689}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:12:48,103]\u001b[0m Trial 67 finished with value: 0.04350227686308186 and parameters: {'booster': 'gbtree', 'learning_rate': 0.6476385804954279, 'n_estimators': 180, 'max_depth': 7, 'gamma': 0.0019600482288032873}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:13:49,022]\u001b[0m Trial 68 finished with value: 0.043425305522768534 and parameters: {'booster': 'gbtree', 'learning_rate': 0.3948899801756017, 'n_estimators': 150, 'max_depth': 7, 'gamma': 0.0010267103882910544}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:13:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:20:49,127]\u001b[0m Trial 69 finished with value: 1.353796678794304 and parameters: {'booster': 'gbtree', 'learning_rate': 0.0011372519356991615, 'n_estimators': 300, 'max_depth': 5, 'gamma': 0.003072700895863217}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:20:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { gamma, max_depth } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:20:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:21:01,891]\u001b[0m Trial 70 finished with value: 0.7123600331823523 and parameters: {'booster': 'gblinear', 'learning_rate': 0.024143630621741116, 'n_estimators': 100, 'max_depth': 7, 'gamma': 0.0019843680536674032}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:21:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:24:44,826]\u001b[0m Trial 71 finished with value: 0.04164483156081133 and parameters: {'booster': 'gbtree', 'learning_rate': 0.1343308133557987, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.004256390943467196}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:27:45,670]\u001b[0m Trial 72 finished with value: 0.041676166137268045 and parameters: {'booster': 'gbtree', 'learning_rate': 0.1754267261908206, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.003845961126726613}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:27:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:30:53,493]\u001b[0m Trial 73 finished with value: 0.042812237127989754 and parameters: {'booster': 'gbtree', 'learning_rate': 0.1697019538444848, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.0045609496923612325}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:30:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:33:37,542]\u001b[0m Trial 74 finished with value: 0.04278357605102224 and parameters: {'booster': 'gbtree', 'learning_rate': 0.26466121029599876, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.007062240240394844}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:33:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:35:58,509]\u001b[0m Trial 75 finished with value: 0.04260174346193478 and parameters: {'booster': 'gbtree', 'learning_rate': 0.33496630066323313, 'n_estimators': 500, 'max_depth': 7, 'gamma': 0.002668068267858515}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:35:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:37:13,679]\u001b[0m Trial 76 finished with value: 0.04141948937416842 and parameters: {'booster': 'gbtree', 'learning_rate': 0.19123994117000712, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.0039042035079156576}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:37:53,635]\u001b[0m Trial 77 finished with value: 0.04220882950887439 and parameters: {'booster': 'gbtree', 'learning_rate': 0.09418404852486877, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.005877918865534967}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:38:20,221]\u001b[0m Trial 78 finished with value: 0.041550749055727726 and parameters: {'booster': 'gbtree', 'learning_rate': 0.23923629019963194, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.011553267316253718}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:38:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:38:40,101]\u001b[0m Trial 79 finished with value: 0.04563262192041477 and parameters: {'booster': 'gbtree', 'learning_rate': 0.5084917305141987, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.011813748565180084}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:38:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:39:05,599]\u001b[0m Trial 80 finished with value: 0.04153141954907836 and parameters: {'booster': 'gbtree', 'learning_rate': 0.29784233311894215, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.025416429458881742}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:39:29,818]\u001b[0m Trial 81 finished with value: 0.04188902315342001 and parameters: {'booster': 'gbtree', 'learning_rate': 0.3076890463226973, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.01733677450237811}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:39:52,703]\u001b[0m Trial 82 finished with value: 0.041530189754449394 and parameters: {'booster': 'gbtree', 'learning_rate': 0.3819478702548178, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.015400253659979981}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:40:19,845]\u001b[0m Trial 83 finished with value: 0.043600588867572475 and parameters: {'booster': 'gbtree', 'learning_rate': 0.3809333105309479, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.05097339975100504}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:40:48,395]\u001b[0m Trial 84 finished with value: 0.04122154331559598 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2387966413746113, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.02464048946828845}. Best is trial 26 with value: 0.04079843337222174.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:41:17,018]\u001b[0m Trial 85 finished with value: 0.04074136064528118 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2418038174035531, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.02432430456334704}. Best is trial 85 with value: 0.04074136064528118.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:41:54,829]\u001b[0m Trial 86 finished with value: 0.040309770721955754 and parameters: {'booster': 'gbtree', 'learning_rate': 0.19970785149378292, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.025767153406383494}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:42:45,397]\u001b[0m Trial 87 finished with value: 0.04137193299546898 and parameters: {'booster': 'gbtree', 'learning_rate': 0.11299614948044429, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.03246023241178866}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:42:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:43:33,545]\u001b[0m Trial 88 finished with value: 0.04129870357186526 and parameters: {'booster': 'gbtree', 'learning_rate': 0.11125613219198179, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.02470514821252984}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:43:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:44:22,078]\u001b[0m Trial 89 finished with value: 0.04229556969528016 and parameters: {'booster': 'gbtree', 'learning_rate': 0.08729022126742045, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.02334423392834121}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:44:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { gamma, max_depth } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:44:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:44:30,514]\u001b[0m Trial 90 finished with value: 0.8685947984022788 and parameters: {'booster': 'gblinear', 'learning_rate': 0.11488188440494211, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.028723418791605445}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:44:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:45:08,379]\u001b[0m Trial 91 finished with value: 0.04122296307498797 and parameters: {'booster': 'gbtree', 'learning_rate': 0.17580758234345067, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.04363375110648345}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:45:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:45:47,881]\u001b[0m Trial 92 finished with value: 0.041212121989822464 and parameters: {'booster': 'gbtree', 'learning_rate': 0.15115379133078805, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.05919550757609168}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:45:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:46:21,907]\u001b[0m Trial 93 finished with value: 0.04062657920490888 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2195855803790197, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.06695228920208007}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:46:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:46:55,971]\u001b[0m Trial 94 finished with value: 0.04272158535514858 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2312332686641343, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.06909455729971715}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:46:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:47:32,444]\u001b[0m Trial 95 finished with value: 0.04231968499012173 and parameters: {'booster': 'gbtree', 'learning_rate': 0.17850735199507184, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.04915273500010511}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:47:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:48:16,685]\u001b[0m Trial 96 finished with value: 0.04157492909706621 and parameters: {'booster': 'gbtree', 'learning_rate': 0.1393346668398533, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.09532130331044096}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:48:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:48:55,422]\u001b[0m Trial 97 finished with value: 0.04034597561459211 and parameters: {'booster': 'gbtree', 'learning_rate': 0.15510043897092513, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.038854516232960434}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:48:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:49:36,714]\u001b[0m Trial 98 finished with value: 0.0421618279520477 and parameters: {'booster': 'gbtree', 'learning_rate': 0.14837962979372282, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.12471008754442015}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:49:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 14:50:14,973]\u001b[0m Trial 99 finished with value: 0.040522214919129156 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2025169287796939, 'n_estimators': 180, 'max_depth': 4, 'gamma': 0.03952699470374035}. Best is trial 86 with value: 0.040309770721955754.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    list_trees = [100, 150, 180, 200, 300, 500, 600]\n",
    "    depth = [3, 4, 5, 6, 7]\n",
    "    param = {\n",
    "        'booster' : trial.suggest_categorical('booster', ['gbtree', 'gblinear']),\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.8),\n",
    "        'n_estimators' : trial.suggest_categorical('n_estimators', list_trees),\n",
    "        'max_depth' : trial.suggest_categorical('max_depth', depth),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 0.001, 1)\n",
    "            }\n",
    "    clf = xgb.XGBClassifier(**param, n_jobs=4)\n",
    "    clf.fit(x_train.reset_index().drop('index', axis = 1), y_train, )\n",
    "    return log_loss(y_val, clf.predict_proba(x_val.reset_index().drop('index', axis = 1)))\n",
    "\n",
    "import optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "structured-lebanon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree',\n",
       " 'learning_rate': 0.19970785149378292,\n",
       " 'n_estimators': 180,\n",
       " 'max_depth': 4,\n",
       " 'gamma': 0.025767153406383494}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = study.best_params\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "overall-bristol",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:04:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:04:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:05:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:05:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:05:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:06:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Train error for xgboost is  0.0011685419827438782\n",
      "Cross Validation error for xgboost is  0.040309770721955754\n",
      "Train error for xgboost with calliberation is  0.021996380365155506\n",
      "Cross Validation error for xgboost with calliberation is  0.0633714584764863\n"
     ]
    }
   ],
   "source": [
    "# xgboost model\n",
    "clf = xgb.XGBClassifier(booster = 'gbtree',\n",
    " learning_rate = 0.19970785149378292,\n",
    " n_estimators = 180,\n",
    " max_depth = 4,\n",
    " gamma = 0.025767153406383494)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# calliberartion model\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", )\n",
    "sig_clf.fit(x_train, y_train)\n",
    "\n",
    "# find log loss error\n",
    "loss = log_loss(y_val, clf.predict_proba(x_val) )\n",
    "\n",
    "loss_c = log_loss(y_val, sig_clf.predict_proba(x_val) )\n",
    "\n",
    "print('Train error for xgboost is ', log_loss(y_train, clf.predict_proba(x_train)))\n",
    "print('Cross Validation error for xgboost is ',loss)\n",
    "\n",
    "print('Train error for xgboost with calliberation is ', log_loss(y_train, sig_clf.predict_proba(x_train)))\n",
    "print('Cross Validation error for xgboost with calliberation is ',loss_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "criminal-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open('bytes_xgboost.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "addressed-arbitration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning:\n",
      "\n",
      "Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3200x3200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(x_val)\n",
    "c = confusion_matrix(y_pred, y_val)\n",
    "\n",
    "plt.figure(figsize = (40, 40), )\n",
    "plot_confusion_matrix(clf, x_val, y_val, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "natural-family",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning:\n",
      "\n",
      "Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 120000x120000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance \n",
    "plt.figure(figsize = (1500, 1500))\n",
    "plot_importance(clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "regular-attendance",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:37:30,593]\u001b[0m A new study created in memory with name: no-name-00b32f09-6245-4e4d-b019-f824b98fce9f\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7299295416000788, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7299295416000788\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008638632269196937, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008638632269196937\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5092031448525193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5092031448525193\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.027972232292597727, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.027972232292597727\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:37:36,368]\u001b[0m Trial 0 finished with value: 0.03509025106073323 and parameters: {'n_estimators': 200, 'num_leaves': 23, 'learning_rate': 0.041011450976735704, 'lambda_l1': 0.0008638632269196937, 'lambda_l2': 0.027972232292597727, 'feature_fraction': 0.7299295416000788, 'bagging_fraction': 0.5092031448525193, 'bagging_freq': 1, 'min_child_samples': 62}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.848893771771948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.848893771771948\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2161659772625339e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2161659772625339e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7673329777030407, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7673329777030407\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011565485390887488, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011565485390887488\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:37:39,562]\u001b[0m Trial 1 finished with value: 0.0513295528306255 and parameters: {'n_estimators': 150, 'num_leaves': 34, 'learning_rate': 0.2742425615284681, 'lambda_l1': 1.2161659772625339e-06, 'lambda_l2': 0.011565485390887488, 'feature_fraction': 0.848893771771948, 'bagging_fraction': 0.7673329777030407, 'bagging_freq': 1, 'min_child_samples': 81}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9006585228219405, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9006585228219405\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06009427585594707, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06009427585594707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8618009633630164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8618009633630164\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.255979466310061e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.255979466310061e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:37:47,558]\u001b[0m Trial 2 finished with value: 0.06524139662208174 and parameters: {'n_estimators': 200, 'num_leaves': 40, 'learning_rate': 0.014345914023042788, 'lambda_l1': 0.06009427585594707, 'lambda_l2': 4.255979466310061e-06, 'feature_fraction': 0.9006585228219405, 'bagging_fraction': 0.8618009633630164, 'bagging_freq': 7, 'min_child_samples': 77}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7664699472351524, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7664699472351524\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0033192725924282595, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0033192725924282595\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8287064187293322, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8287064187293322\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0015932430090472528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015932430090472528\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:37:52,335]\u001b[0m Trial 3 finished with value: 0.05610290258742475 and parameters: {'n_estimators': 150, 'num_leaves': 30, 'learning_rate': 0.09743258960199763, 'lambda_l1': 0.0033192725924282595, 'lambda_l2': 0.0015932430090472528, 'feature_fraction': 0.7664699472351524, 'bagging_fraction': 0.8287064187293322, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.55572353531646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.55572353531646\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016105494480832799, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0016105494480832799\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9664962396595984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9664962396595984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0011016554884198215, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011016554884198215\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:37:54,012]\u001b[0m Trial 4 finished with value: 0.1995779111050231 and parameters: {'n_estimators': 200, 'num_leaves': 19, 'learning_rate': 0.5847593667328325, 'lambda_l1': 0.0016105494480832799, 'lambda_l2': 0.0011016554884198215, 'feature_fraction': 0.55572353531646, 'bagging_fraction': 0.9664962396595984, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5668733750750696, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5668733750750696\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.030026429315771336, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.030026429315771336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6980108970036021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6980108970036021\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1590776000231669e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1590776000231669e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:37:56,089]\u001b[0m Trial 5 finished with value: 16.088439541204952 and parameters: {'n_estimators': 250, 'num_leaves': 37, 'learning_rate': 0.27946027584375477, 'lambda_l1': 0.030026429315771336, 'lambda_l2': 1.1590776000231669e-06, 'feature_fraction': 0.5668733750750696, 'bagging_fraction': 0.6980108970036021, 'bagging_freq': 1, 'min_child_samples': 77}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7538848157910526, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7538848157910526\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19392759291903272, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19392759291903272\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5167140797740442, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5167140797740442\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4141445482510293, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4141445482510293\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:37:59,819]\u001b[0m Trial 6 finished with value: 0.052130897553659565 and parameters: {'n_estimators': 100, 'num_leaves': 40, 'learning_rate': 0.04189456574029954, 'lambda_l1': 0.19392759291903272, 'lambda_l2': 1.4141445482510293, 'feature_fraction': 0.7538848157910526, 'bagging_fraction': 0.5167140797740442, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5601332312410685, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5601332312410685\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.4962418181851076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.4962418181851076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4208044439699852, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4208044439699852\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7585429975970855, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7585429975970855\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:38:01,806]\u001b[0m Trial 7 finished with value: 0.0570328393073749 and parameters: {'n_estimators': 200, 'num_leaves': 34, 'learning_rate': 0.10064301995572998, 'lambda_l1': 2.4962418181851076, 'lambda_l2': 0.7585429975970855, 'feature_fraction': 0.5601332312410685, 'bagging_fraction': 0.4208044439699852, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4235599998489211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4235599998489211\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7363786511932943e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7363786511932943e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780252668701102, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780252668701102\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.810052241147402e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.810052241147402e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:38:05,742]\u001b[0m Trial 8 finished with value: 0.04062589187970941 and parameters: {'n_estimators': 100, 'num_leaves': 32, 'learning_rate': 0.04569694524725595, 'lambda_l1': 2.7363786511932943e-05, 'lambda_l2': 8.810052241147402e-05, 'feature_fraction': 0.4235599998489211, 'bagging_fraction': 0.7780252668701102, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.943987733118548, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.943987733118548\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07211349730665534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07211349730665534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8783017365188788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8783017365188788\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1728019743040134e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1728019743040134e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:38:17,518]\u001b[0m Trial 9 finished with value: 0.045351405021189214 and parameters: {'n_estimators': 250, 'num_leaves': 22, 'learning_rate': 0.01437753737243418, 'lambda_l1': 0.07211349730665534, 'lambda_l2': 1.1728019743040134e-06, 'feature_fraction': 0.943987733118548, 'bagging_fraction': 0.8783017365188788, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6562228944616332, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6562228944616332\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3279958358125772e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3279958358125772e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5824410115969033, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5824410115969033\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.892123696580257e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.892123696580257e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:38:26,399]\u001b[0m Trial 10 finished with value: 0.03893821067760261 and parameters: {'n_estimators': 200, 'num_leaves': 25, 'learning_rate': 0.038727141903272415, 'lambda_l1': 1.3279958358125772e-08, 'lambda_l2': 1.892123696580257e-08, 'feature_fraction': 0.6562228944616332, 'bagging_fraction': 0.5824410115969033, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6639649448901053, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6639649448901053\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5391699087759442e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5391699087759442e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5896568528718958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5896568528718958\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.1005578770635572e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1005578770635572e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:38:35,448]\u001b[0m Trial 11 finished with value: 0.03732190263169533 and parameters: {'n_estimators': 200, 'num_leaves': 25, 'learning_rate': 0.036538762103543516, 'lambda_l1': 1.5391699087759442e-08, 'lambda_l2': 2.1005578770635572e-08, 'feature_fraction': 0.6639649448901053, 'bagging_fraction': 0.5896568528718958, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6774502518185419, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6774502518185419\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.4543850517755967e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.4543850517755967e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5852001615029006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5852001615029006\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12953753303327473, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12953753303327473\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:38:40,907]\u001b[0m Trial 12 finished with value: 0.040028440478681586 and parameters: {'n_estimators': 200, 'num_leaves': 17, 'learning_rate': 0.02567531230590852, 'lambda_l1': 2.4543850517755967e-05, 'lambda_l2': 0.12953753303327473, 'feature_fraction': 0.6774502518185419, 'bagging_fraction': 0.5852001615029006, 'bagging_freq': 5, 'min_child_samples': 52}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8147747321483765, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8147747321483765\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1538707390020376e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1538707390020376e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4047006617288481, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4047006617288481\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.9842871286493145e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9842871286493145e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:38:50,668]\u001b[0m Trial 13 finished with value: 0.050661086904378656 and parameters: {'n_estimators': 200, 'num_leaves': 26, 'learning_rate': 0.022733015127911732, 'lambda_l1': 1.1538707390020376e-08, 'lambda_l2': 2.9842871286493145e-08, 'feature_fraction': 0.8147747321483765, 'bagging_fraction': 0.4047006617288481, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6319775509140199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6319775509140199\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.625006767464543e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.625006767464543e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4951914493630017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4951914493630017\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05086074623651449, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05086074623651449\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:38:55,216]\u001b[0m Trial 14 finished with value: 0.03911060366974718 and parameters: {'n_estimators': 200, 'num_leaves': 22, 'learning_rate': 0.06858911112184311, 'lambda_l1': 4.625006767464543e-07, 'lambda_l2': 0.05086074623651449, 'feature_fraction': 0.6319775509140199, 'bagging_fraction': 0.4951914493630017, 'bagging_freq': 5, 'min_child_samples': 56}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4422947630967321, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4422947630967321\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00024232908823676097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00024232908823676097\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6401256203357852, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6401256203357852\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.330977054043476e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.330977054043476e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:39:00,708]\u001b[0m Trial 15 finished with value: 0.11347098983835935 and parameters: {'n_estimators': 200, 'num_leaves': 22, 'learning_rate': 0.010137169402180048, 'lambda_l1': 0.00024232908823676097, 'lambda_l2': 6.330977054043476e-05, 'feature_fraction': 0.4422947630967321, 'bagging_fraction': 0.6401256203357852, 'bagging_freq': 6, 'min_child_samples': 47}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7363257009660953, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7363257009660953\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.156691640283711e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.156691640283711e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.49362295988749916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.49362295988749916\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.008906610965214577, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.008906610965214577\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:39:04,503]\u001b[0m Trial 16 finished with value: 0.05217957323990824 and parameters: {'n_estimators': 200, 'num_leaves': 28, 'learning_rate': 0.15866391992200618, 'lambda_l1': 7.156691640283711e-07, 'lambda_l2': 0.008906610965214577, 'feature_fraction': 0.7363257009660953, 'bagging_fraction': 0.49362295988749916, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6057649720553172, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6057649720553172\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.4185359921326087e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.4185359921326087e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5845737639665763, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5845737639665763\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.695984428818091, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.695984428818091\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:39:07,488]\u001b[0m Trial 17 finished with value: 0.07520864901311868 and parameters: {'n_estimators': 150, 'num_leaves': 15, 'learning_rate': 0.02533776433687323, 'lambda_l1': 2.4185359921326087e-05, 'lambda_l2': 2.695984428818091, 'feature_fraction': 0.6057649720553172, 'bagging_fraction': 0.5845737639665763, 'bagging_freq': 6, 'min_child_samples': 93}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.49326763818273833, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49326763818273833\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.164308525389664, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.164308525389664\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45232004878391885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45232004878391885\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.422727126544881, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.422727126544881\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:39:09,813]\u001b[0m Trial 18 finished with value: 0.08712697875924096 and parameters: {'n_estimators': 250, 'num_leaves': 20, 'learning_rate': 0.05988276423807472, 'lambda_l1': 5.164308525389664, 'lambda_l2': 8.422727126544881, 'feature_fraction': 0.49326763818273833, 'bagging_fraction': 0.45232004878391885, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7190746258276073, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7190746258276073\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.599113386009832e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.599113386009832e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6615705411959715, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6615705411959715\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3295207167087318e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.3295207167087318e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:39:13,802]\u001b[0m Trial 19 finished with value: 0.04764518108911397 and parameters: {'n_estimators': 100, 'num_leaves': 25, 'learning_rate': 0.13762182740300635, 'lambda_l1': 8.599113386009832e-08, 'lambda_l2': 1.3295207167087318e-07, 'feature_fraction': 0.7190746258276073, 'bagging_fraction': 0.6615705411959715, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9903467026927094, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9903467026927094\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0003391853605182461, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0003391853605182461\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5357649124933168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5357649124933168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8417023185070234e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8417023185070234e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:39:23,521]\u001b[0m Trial 20 finished with value: 0.03918097144094945 and parameters: {'n_estimators': 200, 'num_leaves': 28, 'learning_rate': 0.031132802410833955, 'lambda_l1': 0.0003391853605182461, 'lambda_l2': 1.8417023185070234e-05, 'feature_fraction': 0.9903467026927094, 'bagging_fraction': 0.5357649124933168, 'bagging_freq': 6, 'min_child_samples': 65}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6640566715988485, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6640566715988485\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3959733252871778e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3959733252871778e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5845160443578072, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5845160443578072\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.233002346416174e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.233002346416174e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:39:32,626]\u001b[0m Trial 21 finished with value: 0.03728064149566807 and parameters: {'n_estimators': 200, 'num_leaves': 25, 'learning_rate': 0.03747855494728684, 'lambda_l1': 1.3959733252871778e-08, 'lambda_l2': 4.233002346416174e-08, 'feature_fraction': 0.6640566715988485, 'bagging_fraction': 0.5845160443578072, 'bagging_freq': 4, 'min_child_samples': 55}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8094821857359684, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8094821857359684\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.099035283517245e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.099035283517245e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6298700784870186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6298700784870186\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.936985322650007e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.936985322650007e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:39:43,910]\u001b[0m Trial 22 finished with value: 0.04716197258936296 and parameters: {'n_estimators': 200, 'num_leaves': 24, 'learning_rate': 0.017927470798571425, 'lambda_l1': 6.099035283517245e-08, 'lambda_l2': 9.936985322650007e-08, 'feature_fraction': 0.8094821857359684, 'bagging_fraction': 0.6298700784870186, 'bagging_freq': 4, 'min_child_samples': 43}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6773197183525586, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773197183525586\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1683480637742146e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1683480637742146e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5567353228866893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5567353228866893\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9953470626328964e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9953470626328964e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:39:52,824]\u001b[0m Trial 23 finished with value: 0.04653380582387585 and parameters: {'n_estimators': 200, 'num_leaves': 29, 'learning_rate': 0.05678407325774431, 'lambda_l1': 3.1683480637742146e-06, 'lambda_l2': 1.9953470626328964e-07, 'feature_fraction': 0.6773197183525586, 'bagging_fraction': 0.5567353228866893, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6219082268567097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6219082268567097\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.77441256283416e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.77441256283416e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46215806786942215, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46215806786942215\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4772679327627457e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4772679327627457e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:40:00,938]\u001b[0m Trial 24 finished with value: 0.03827533512802098 and parameters: {'n_estimators': 200, 'num_leaves': 23, 'learning_rate': 0.03435740452534357, 'lambda_l1': 9.77441256283416e-08, 'lambda_l2': 1.4772679327627457e-08, 'feature_fraction': 0.6219082268567097, 'bagging_fraction': 0.46215806786942215, 'bagging_freq': 2, 'min_child_samples': 60}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4971680886340146, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4971680886340146\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004397251256774516, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004397251256774516\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6242398520419434, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6242398520419434\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17524367519493497, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17524367519493497\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:40:05,594]\u001b[0m Trial 25 finished with value: 0.12010985144785552 and parameters: {'n_estimators': 200, 'num_leaves': 20, 'learning_rate': 0.010102073972066763, 'lambda_l1': 0.004397251256774516, 'lambda_l2': 0.17524367519493497, 'feature_fraction': 0.4971680886340146, 'bagging_fraction': 0.6242398520419434, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6954170780190805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6954170780190805\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0003040194689167156, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0003040194689167156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7022806795930078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7022806795930078\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0006740345635475687, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006740345635475687\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:40:11,769]\u001b[0m Trial 26 finished with value: 0.04701263616763454 and parameters: {'n_estimators': 200, 'num_leaves': 26, 'learning_rate': 0.07334052956889742, 'lambda_l1': 0.0003040194689167156, 'lambda_l2': 0.0006740345635475687, 'feature_fraction': 0.6954170780190805, 'bagging_fraction': 0.7022806795930078, 'bagging_freq': 3, 'min_child_samples': 72}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7886059283085967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7886059283085967\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.540961342656534e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.540961342656534e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6943986324920053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6943986324920053\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.53711074016229e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.53711074016229e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:40:20,056]\u001b[0m Trial 27 finished with value: 0.047341640352765516 and parameters: {'n_estimators': 200, 'num_leaves': 18, 'learning_rate': 0.018128423292651675, 'lambda_l1': 5.540961342656534e-06, 'lambda_l2': 8.53711074016229e-07, 'feature_fraction': 0.7886059283085967, 'bagging_fraction': 0.6943986324920053, 'bagging_freq': 5, 'min_child_samples': 60}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5998099139040243, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5998099139040243\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.901056423967549e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.901056423967549e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5465486717226066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5465486717226066\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.008459174817439678, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.008459174817439678\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:40:22,938]\u001b[0m Trial 28 finished with value: 0.04255814834249287 and parameters: {'n_estimators': 100, 'num_leaves': 31, 'learning_rate': 0.049424055515873165, 'lambda_l1': 1.901056423967549e-08, 'lambda_l2': 0.008459174817439678, 'feature_fraction': 0.5998099139040243, 'bagging_fraction': 0.5465486717226066, 'bagging_freq': 6, 'min_child_samples': 86}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8676688034213402, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8676688034213402\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.2914284271495302e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2914284271495302e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7552017713778267, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7552017713778267\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03837138565932915, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03837138565932915\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:40:27,592]\u001b[0m Trial 29 finished with value: 0.040589385536845685 and parameters: {'n_estimators': 150, 'num_leaves': 27, 'learning_rate': 0.1401623997966459, 'lambda_l1': 2.2914284271495302e-07, 'lambda_l2': 0.03837138565932915, 'feature_fraction': 0.8676688034213402, 'bagging_fraction': 0.7552017713778267, 'bagging_freq': 4, 'min_child_samples': 72}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7179087240044073, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7179087240044073\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.9573394549166576e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9573394549166576e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6005584791574026, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6005584791574026\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0171013790488512e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0171013790488512e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:40:35,515]\u001b[0m Trial 30 finished with value: 0.037517304999797774 and parameters: {'n_estimators': 250, 'num_leaves': 15, 'learning_rate': 0.02883085759539813, 'lambda_l1': 2.9573394549166576e-06, 'lambda_l2': 1.0171013790488512e-08, 'feature_fraction': 0.7179087240044073, 'bagging_fraction': 0.6005584791574026, 'bagging_freq': 3, 'min_child_samples': 86}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7170716264060233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170716264060233\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2569753889229833e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2569753889229833e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6137756578112479, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6137756578112479\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.158639388318597e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.158639388318597e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:40:43,584]\u001b[0m Trial 31 finished with value: 0.036804085879082384 and parameters: {'n_estimators': 250, 'num_leaves': 15, 'learning_rate': 0.02860196636829734, 'lambda_l1': 1.2569753889229833e-06, 'lambda_l2': 1.158639388318597e-08, 'feature_fraction': 0.7170716264060233, 'bagging_fraction': 0.6137756578112479, 'bagging_freq': 2, 'min_child_samples': 85}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6521687856363777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6521687856363777\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.778570860712019e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.778570860712019e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.666094530038482, subsample=1.0 will be ignored. Current value: bagging_fraction=0.666094530038482\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.632253735862607e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.632253735862607e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:40:54,677]\u001b[0m Trial 32 finished with value: 0.039611295819902304 and parameters: {'n_estimators': 250, 'num_leaves': 24, 'learning_rate': 0.019456156402987448, 'lambda_l1': 3.778570860712019e-08, 'lambda_l2': 4.632253735862607e-08, 'feature_fraction': 0.6521687856363777, 'bagging_fraction': 0.666094530038482, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7682536404199846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7682536404199846\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008474946745456892, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008474946745456892\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46285235909094957, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46285235909094957\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4016842518209595e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4016842518209595e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:01,839]\u001b[0m Trial 33 finished with value: 0.036371867617590016 and parameters: {'n_estimators': 250, 'num_leaves': 17, 'learning_rate': 0.03873504820490584, 'lambda_l1': 0.0008474946745456892, 'lambda_l2': 3.4016842518209595e-07, 'feature_fraction': 0.7682536404199846, 'bagging_fraction': 0.46285235909094957, 'bagging_freq': 2, 'min_child_samples': 81}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8519270113406453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8519270113406453\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008405743003815785, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008405743003815785\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45418329626727905, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45418329626727905\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.464055901596564e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.464055901596564e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:09,463]\u001b[0m Trial 34 finished with value: 0.06595660504797098 and parameters: {'n_estimators': 250, 'num_leaves': 16, 'learning_rate': 0.013499186839784573, 'lambda_l1': 0.0008405743003815785, 'lambda_l2': 7.464055901596564e-06, 'feature_fraction': 0.8519270113406453, 'bagging_fraction': 0.45418329626727905, 'bagging_freq': 2, 'min_child_samples': 85}. Best is trial 0 with value: 0.03509025106073323.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7630017225775518, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7630017225775518\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02205004309870067, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02205004309870067\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4946485474894492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4946485474894492\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9415486524332264e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9415486524332264e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:13,874]\u001b[0m Trial 35 finished with value: 0.034928779148588475 and parameters: {'n_estimators': 250, 'num_leaves': 20, 'learning_rate': 0.0882124789184781, 'lambda_l1': 0.02205004309870067, 'lambda_l2': 3.9415486524332264e-07, 'feature_fraction': 0.7630017225775518, 'bagging_fraction': 0.4946485474894492, 'bagging_freq': 1, 'min_child_samples': 78}. Best is trial 35 with value: 0.034928779148588475.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.763970565311174, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.763970565311174\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.007069100155903003, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007069100155903003\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4305700563092225, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4305700563092225\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2916521284618456e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2916521284618456e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:18,494]\u001b[0m Trial 36 finished with value: 0.04049791450413462 and parameters: {'n_estimators': 250, 'num_leaves': 19, 'learning_rate': 0.08560812713823092, 'lambda_l1': 0.007069100155903003, 'lambda_l2': 3.2916521284618456e-07, 'feature_fraction': 0.763970565311174, 'bagging_fraction': 0.4305700563092225, 'bagging_freq': 1, 'min_child_samples': 94}. Best is trial 35 with value: 0.034928779148588475.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7895395084766965, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7895395084766965\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5585821749018366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5585821749018366\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5101156906685672, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5101156906685672\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6581587146177193e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6581587146177193e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:20,934]\u001b[0m Trial 37 finished with value: 0.03769597986131783 and parameters: {'n_estimators': 250, 'num_leaves': 20, 'learning_rate': 0.1995678652486897, 'lambda_l1': 0.5585821749018366, 'lambda_l2': 2.6581587146177193e-06, 'feature_fraction': 0.7895395084766965, 'bagging_fraction': 0.5101156906685672, 'bagging_freq': 1, 'min_child_samples': 78}. Best is trial 35 with value: 0.034928779148588475.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8284178344208964, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8284178344208964\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02048092315411964, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02048092315411964\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48041815031270096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48041815031270096\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.000116870894271286, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000116870894271286\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:22,828]\u001b[0m Trial 38 finished with value: 11.930984111826467 and parameters: {'n_estimators': 250, 'num_leaves': 18, 'learning_rate': 0.4415982850582735, 'lambda_l1': 0.02048092315411964, 'lambda_l2': 0.000116870894271286, 'feature_fraction': 0.8284178344208964, 'bagging_fraction': 0.48041815031270096, 'bagging_freq': 2, 'min_child_samples': 72}. Best is trial 35 with value: 0.034928779148588475.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8886007735740418, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8886007735740418\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00010160850340217974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00010160850340217974\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40445102792571686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40445102792571686\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0028824107567043847, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0028824107567043847\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:28,592]\u001b[0m Trial 39 finished with value: 0.04428007626076743 and parameters: {'n_estimators': 250, 'num_leaves': 16, 'learning_rate': 0.09233248023481963, 'lambda_l1': 0.00010160850340217974, 'lambda_l2': 0.0028824107567043847, 'feature_fraction': 0.8886007735740418, 'bagging_fraction': 0.40445102792571686, 'bagging_freq': 1, 'min_child_samples': 78}. Best is trial 35 with value: 0.034928779148588475.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.747886678201931, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.747886678201931\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001445901603439679, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001445901603439679\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5356002567977259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5356002567977259\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.300765529424276e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.300765529424276e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:35,641]\u001b[0m Trial 40 finished with value: 0.03733980488376214 and parameters: {'n_estimators': 250, 'num_leaves': 17, 'learning_rate': 0.04676604468268182, 'lambda_l1': 0.001445901603439679, 'lambda_l2': 5.300765529424276e-07, 'feature_fraction': 0.747886678201931, 'bagging_fraction': 0.5356002567977259, 'bagging_freq': 2, 'min_child_samples': 92}. Best is trial 35 with value: 0.034928779148588475.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7059702558204511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7059702558204511\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010286058987857111, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010286058987857111\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5583755803520503, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5583755803520503\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4591513985508246e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4591513985508246e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:39,633]\u001b[0m Trial 41 finished with value: 0.040221551101184055 and parameters: {'n_estimators': 250, 'num_leaves': 21, 'learning_rate': 0.11415576528187278, 'lambda_l1': 0.010286058987857111, 'lambda_l2': 5.4591513985508246e-08, 'feature_fraction': 0.7059702558204511, 'bagging_fraction': 0.5583755803520503, 'bagging_freq': 1, 'min_child_samples': 88}. Best is trial 35 with value: 0.034928779148588475.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7861089451850033, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7861089451850033\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12354432152978755, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12354432152978755\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5094238314799027, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5094238314799027\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.5141731288430137e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.5141731288430137e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:44,575]\u001b[0m Trial 42 finished with value: 0.033465138692138824 and parameters: {'n_estimators': 250, 'num_leaves': 23, 'learning_rate': 0.054224641960325226, 'lambda_l1': 0.12354432152978755, 'lambda_l2': 2.5141731288430137e-06, 'feature_fraction': 0.7861089451850033, 'bagging_fraction': 0.5094238314799027, 'bagging_freq': 2, 'min_child_samples': 82}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7789892144116919, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7789892144116919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15776128745768112, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15776128745768112\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43058136947228154, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43058136947228154\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.685190695072405e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.685190695072405e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:48,992]\u001b[0m Trial 43 finished with value: 0.034252964920073715 and parameters: {'n_estimators': 250, 'num_leaves': 18, 'learning_rate': 0.05653275526980248, 'lambda_l1': 0.15776128745768112, 'lambda_l2': 3.685190695072405e-06, 'feature_fraction': 0.7789892144116919, 'bagging_fraction': 0.43058136947228154, 'bagging_freq': 2, 'min_child_samples': 81}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7817133260465312, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7817133260465312\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3193813459058877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3193813459058877\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44367699443621217, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44367699443621217\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.400053717405751e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.400053717405751e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:53,110]\u001b[0m Trial 44 finished with value: 0.03625405037747596 and parameters: {'n_estimators': 250, 'num_leaves': 19, 'learning_rate': 0.07476216528886001, 'lambda_l1': 0.3193813459058877, 'lambda_l2': 3.400053717405751e-06, 'feature_fraction': 0.7817133260465312, 'bagging_fraction': 0.44367699443621217, 'bagging_freq': 1, 'min_child_samples': 83}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9224188134360447, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9224188134360447\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3741830123410273, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3741830123410273\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42629015664537934, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42629015664537934\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.702378124105516e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.702378124105516e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:41:57,773]\u001b[0m Trial 45 finished with value: 0.03714987061264855 and parameters: {'n_estimators': 250, 'num_leaves': 21, 'learning_rate': 0.07452864117113052, 'lambda_l1': 0.3741830123410273, 'lambda_l2': 9.702378124105516e-06, 'feature_fraction': 0.9224188134360447, 'bagging_fraction': 0.42629015664537934, 'bagging_freq': 1, 'min_child_samples': 74}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8395471220250853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8395471220250853\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11300714185396896, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11300714185396896\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5157270732985246, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5157270732985246\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3197695818281927e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3197695818281927e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:03,003]\u001b[0m Trial 46 finished with value: 0.03594671350130215 and parameters: {'n_estimators': 250, 'num_leaves': 19, 'learning_rate': 0.05837210565650542, 'lambda_l1': 0.11300714185396896, 'lambda_l2': 2.3197695818281927e-06, 'feature_fraction': 0.8395471220250853, 'bagging_fraction': 0.5157270732985246, 'bagging_freq': 1, 'min_child_samples': 80}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8322693791953705, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8322693791953705\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08585075956215758, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08585075956215758\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5138598934849002, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5138598934849002\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.456601153940857e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.456601153940857e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:08,385]\u001b[0m Trial 47 finished with value: 0.035806466795861996 and parameters: {'n_estimators': 250, 'num_leaves': 23, 'learning_rate': 0.05640455571602175, 'lambda_l1': 0.08585075956215758, 'lambda_l2': 2.456601153940857e-05, 'feature_fraction': 0.8322693791953705, 'bagging_fraction': 0.5138598934849002, 'bagging_freq': 1, 'min_child_samples': 67}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8767664492934462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8767664492934462\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2730619445673934, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2730619445673934\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4005746921856517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4005746921856517\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.276639556973923e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.276639556973923e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:10,578]\u001b[0m Trial 48 finished with value: 0.04470042008746489 and parameters: {'n_estimators': 150, 'num_leaves': 23, 'learning_rate': 0.10760097343113313, 'lambda_l1': 1.2730619445673934, 'lambda_l2': 4.276639556973923e-05, 'feature_fraction': 0.8767664492934462, 'bagging_fraction': 0.4005746921856517, 'bagging_freq': 2, 'min_child_samples': 66}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8050049992677453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8050049992677453\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.043822187856929866, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.043822187856929866\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9883400259723372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9883400259723372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00020258367224119296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00020258367224119296\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:17,555]\u001b[0m Trial 49 finished with value: 0.038141836627387876 and parameters: {'n_estimators': 250, 'num_leaves': 23, 'learning_rate': 0.050433374991099206, 'lambda_l1': 0.043822187856929866, 'lambda_l2': 0.00020258367224119296, 'feature_fraction': 0.8050049992677453, 'bagging_fraction': 0.9883400259723372, 'bagging_freq': 1, 'min_child_samples': 69}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9050858598357066, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9050858598357066\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.021073428058064548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.021073428058064548\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4783838947126444, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4783838947126444\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8246887612711772e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8246887612711772e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:20,637]\u001b[0m Trial 50 finished with value: 0.039742326832817844 and parameters: {'n_estimators': 250, 'num_leaves': 21, 'learning_rate': 0.2130840860536588, 'lambda_l1': 0.021073428058064548, 'lambda_l2': 2.8246887612711772e-05, 'feature_fraction': 0.9050858598357066, 'bagging_fraction': 0.4783838947126444, 'bagging_freq': 2, 'min_child_samples': 75}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8256265636218724, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8256265636218724\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12251228090581895, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12251228090581895\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5088324159930185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5088324159930185\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.537267107954437e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.537267107954437e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:25,405]\u001b[0m Trial 51 finished with value: 0.03533419935715505 and parameters: {'n_estimators': 250, 'num_leaves': 18, 'learning_rate': 0.06110395662059688, 'lambda_l1': 0.12251228090581895, 'lambda_l2': 2.537267107954437e-06, 'feature_fraction': 0.8256265636218724, 'bagging_fraction': 0.5088324159930185, 'bagging_freq': 1, 'min_child_samples': 80}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7476931879071319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7476931879071319\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09708364623977356, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09708364623977356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5012219893066008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5012219893066008\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2276283818677152e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2276283818677152e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:29,920]\u001b[0m Trial 52 finished with value: 0.03438903949902902 and parameters: {'n_estimators': 250, 'num_leaves': 22, 'learning_rate': 0.0619850404513376, 'lambda_l1': 0.09708364623977356, 'lambda_l2': 1.2276283818677152e-05, 'feature_fraction': 0.7476931879071319, 'bagging_fraction': 0.5012219893066008, 'bagging_freq': 1, 'min_child_samples': 90}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7429789228151116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7429789228151116\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.502061052683986, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.502061052683986\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.483789154146074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.483789154146074\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.429766874512248e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.429766874512248e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:33,090]\u001b[0m Trial 53 finished with value: 0.044754981763066984 and parameters: {'n_estimators': 250, 'num_leaves': 21, 'learning_rate': 0.06526876524179186, 'lambda_l1': 1.502061052683986, 'lambda_l2': 1.429766874512248e-06, 'feature_fraction': 0.7429789228151116, 'bagging_fraction': 0.483789154146074, 'bagging_freq': 1, 'min_child_samples': 89}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7352992226295036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7352992226295036\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.202022543029191, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.202022543029191\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5610366703621497, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5610366703621497\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0660224818408979e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0660224818408979e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:36,722]\u001b[0m Trial 54 finished with value: 0.039592682948693794 and parameters: {'n_estimators': 250, 'num_leaves': 18, 'learning_rate': 0.08734420411243056, 'lambda_l1': 0.202022543029191, 'lambda_l2': 1.0660224818408979e-05, 'feature_fraction': 0.7352992226295036, 'bagging_fraction': 0.5610366703621497, 'bagging_freq': 2, 'min_child_samples': 99}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7718363433564076, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7718363433564076\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.97322054976959, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.97322054976959\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.49612921215074074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.49612921215074074\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.618267210831596e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.618267210831596e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:38,213]\u001b[0m Trial 55 finished with value: 0.1320689851630937 and parameters: {'n_estimators': 100, 'num_leaves': 22, 'learning_rate': 0.04343921059091019, 'lambda_l1': 8.97322054976959, 'lambda_l2': 5.618267210831596e-06, 'feature_fraction': 0.7718363433564076, 'bagging_fraction': 0.49612921215074074, 'bagging_freq': 1, 'min_child_samples': 95}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6864398998952235, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6864398998952235\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6671548897051787, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6671548897051787\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9260076341049568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9260076341049568\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0158042143661363e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0158042143661363e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:41,425]\u001b[0m Trial 56 finished with value: 0.04060381114668223 and parameters: {'n_estimators': 250, 'num_leaves': 20, 'learning_rate': 0.11530731978590479, 'lambda_l1': 0.6671548897051787, 'lambda_l2': 1.0158042143661363e-06, 'feature_fraction': 0.6864398998952235, 'bagging_fraction': 0.9260076341049568, 'bagging_freq': 3, 'min_child_samples': 91}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.809345466783996, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.809345466783996\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14263064507034925, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14263064507034925\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5308829214330859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5308829214330859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0005096700333272389, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005096700333272389\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:45,488]\u001b[0m Trial 57 finished with value: 0.038196396079350256 and parameters: {'n_estimators': 250, 'num_leaves': 24, 'learning_rate': 0.08346985769168912, 'lambda_l1': 0.14263064507034925, 'lambda_l2': 0.0005096700333272389, 'feature_fraction': 0.809345466783996, 'bagging_fraction': 0.5308829214330859, 'bagging_freq': 2, 'min_child_samples': 81}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.751561946011765, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.751561946011765\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.011788567169024593, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011788567169024593\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4206132731776534, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4206132731776534\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.568106462728576e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.568106462728576e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:49,548]\u001b[0m Trial 58 finished with value: 0.03764328618935141 and parameters: {'n_estimators': 150, 'num_leaves': 37, 'learning_rate': 0.06621144492899755, 'lambda_l1': 0.011788567169024593, 'lambda_l2': 4.568106462728576e-06, 'feature_fraction': 0.751561946011765, 'bagging_fraction': 0.4206132731776534, 'bagging_freq': 1, 'min_child_samples': 61}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7939336696285657, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7939336696285657\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04289110982695912, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04289110982695912\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5717569137454762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5717569137454762\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.5232943501477388e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.5232943501477388e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:55,403]\u001b[0m Trial 59 finished with value: 0.03637936995942652 and parameters: {'n_estimators': 250, 'num_leaves': 17, 'learning_rate': 0.05161129271367047, 'lambda_l1': 0.04289110982695912, 'lambda_l2': 1.5232943501477388e-05, 'feature_fraction': 0.7939336696285657, 'bagging_fraction': 0.5717569137454762, 'bagging_freq': 3, 'min_child_samples': 76}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8461941683190475, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8461941683190475\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.043621310239187, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.043621310239187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5006192658265529, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5006192658265529\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.890651362563567e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.890651362563567e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:42:59,550]\u001b[0m Trial 60 finished with value: 0.05644040370275751 and parameters: {'n_estimators': 250, 'num_leaves': 22, 'learning_rate': 0.03403373674938065, 'lambda_l1': 2.043621310239187, 'lambda_l2': 5.890651362563567e-07, 'feature_fraction': 0.8461941683190475, 'bagging_fraction': 0.5006192658265529, 'bagging_freq': 1, 'min_child_samples': 97}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8257428794938898, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8257428794938898\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09609318533889477, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09609318533889477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5320434322987357, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5320434322987357\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8855314634054952e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8855314634054952e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:43:04,905]\u001b[0m Trial 61 finished with value: 0.033671860348095384 and parameters: {'n_estimators': 250, 'num_leaves': 23, 'learning_rate': 0.0574813768977683, 'lambda_l1': 0.09609318533889477, 'lambda_l2': 2.8855314634054952e-05, 'feature_fraction': 0.8257428794938898, 'bagging_fraction': 0.5320434322987357, 'bagging_freq': 1, 'min_child_samples': 62}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8209029793023814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8209029793023814\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07982749610929625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07982749610929625\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47192679287216116, subsample=1.0 will be ignored. Current value: bagging_fraction=0.47192679287216116\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.595326444514167e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.595326444514167e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:43:10,630]\u001b[0m Trial 62 finished with value: 0.03617349386709426 and parameters: {'n_estimators': 250, 'num_leaves': 19, 'learning_rate': 0.04478398940237181, 'lambda_l1': 0.07982749610929625, 'lambda_l2': 7.595326444514167e-05, 'feature_fraction': 0.8209029793023814, 'bagging_fraction': 0.47192679287216116, 'bagging_freq': 1, 'min_child_samples': 69}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7283672329070512, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7283672329070512\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0031775592147464293, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0031775592147464293\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5261144330731266, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5261144330731266\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8527578583100706e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8527578583100706e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:43:17,185]\u001b[0m Trial 63 finished with value: 0.038638013217460555 and parameters: {'n_estimators': 250, 'num_leaves': 26, 'learning_rate': 0.061541727915869385, 'lambda_l1': 0.0031775592147464293, 'lambda_l2': 2.8527578583100706e-06, 'feature_fraction': 0.7283672329070512, 'bagging_fraction': 0.5261144330731266, 'bagging_freq': 2, 'min_child_samples': 61}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.863084063509338, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.863084063509338\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2120000422916309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2120000422916309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43893096514197194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43893096514197194\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6784565281860406e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6784565281860406e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:43:22,392]\u001b[0m Trial 64 finished with value: 0.03744967968117281 and parameters: {'n_estimators': 250, 'num_leaves': 24, 'learning_rate': 0.039752496778038764, 'lambda_l1': 0.2120000422916309, 'lambda_l2': 1.6784565281860406e-06, 'feature_fraction': 0.863084063509338, 'bagging_fraction': 0.43893096514197194, 'bagging_freq': 1, 'min_child_samples': 82}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7624291849249397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7624291849249397\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.939520315542801, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.939520315542801\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5444064999374439, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5444064999374439\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00016461276509863922, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00016461276509863922\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:43:25,129]\u001b[0m Trial 65 finished with value: 0.0647260544797168 and parameters: {'n_estimators': 250, 'num_leaves': 21, 'learning_rate': 0.07402311413441298, 'lambda_l1': 3.939520315542801, 'lambda_l2': 0.00016461276509863922, 'feature_fraction': 0.7624291849249397, 'bagging_fraction': 0.5444064999374439, 'bagging_freq': 2, 'min_child_samples': 89}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9644046915638662, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9644046915638662\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02576559918088543, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02576559918088543\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4939315354395458, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4939315354395458\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.312994854451199e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.312994854451199e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:43:28,164]\u001b[0m Trial 66 finished with value: 0.039121742203791436 and parameters: {'n_estimators': 100, 'num_leaves': 27, 'learning_rate': 0.13360202542338173, 'lambda_l1': 0.02576559918088543, 'lambda_l2': 4.312994854451199e-05, 'feature_fraction': 0.9644046915638662, 'bagging_fraction': 0.4939315354395458, 'bagging_freq': 1, 'min_child_samples': 53}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8038289871339922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8038289871339922\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6463144395592627, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6463144395592627\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4525759843664373, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4525759843664373\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1086870760555485e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1086870760555485e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:43:31,407]\u001b[0m Trial 67 finished with value: 0.03916648685917516 and parameters: {'n_estimators': 250, 'num_leaves': 22, 'learning_rate': 0.09997604353008835, 'lambda_l1': 0.6463144395592627, 'lambda_l2': 1.1086870760555485e-07, 'feature_fraction': 0.8038289871339922, 'bagging_fraction': 0.4525759843664373, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 42 with value: 0.033465138692138824.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7775729945527079, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7775729945527079\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06347385911744392, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06347385911744392\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6031044675911276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6031044675911276\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.494311773332968e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.494311773332968e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:43:38,442]\u001b[0m Trial 68 finished with value: 0.03337641067842687 and parameters: {'n_estimators': 250, 'num_leaves': 25, 'learning_rate': 0.03273819078795996, 'lambda_l1': 0.06347385911744392, 'lambda_l2': 2.494311773332968e-07, 'feature_fraction': 0.7775729945527079, 'bagging_fraction': 0.6031044675911276, 'bagging_freq': 2, 'min_child_samples': 71}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7796987827126576, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7796987827126576\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05527711812936925, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05527711812936925\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5740089172319741, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5740089172319741\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0782337639921156e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0782337639921156e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:43:45,553]\u001b[0m Trial 69 finished with value: 0.03497887216829316 and parameters: {'n_estimators': 250, 'num_leaves': 25, 'learning_rate': 0.03395278903959521, 'lambda_l1': 0.05527711812936925, 'lambda_l2': 2.0782337639921156e-07, 'feature_fraction': 0.7796987827126576, 'bagging_fraction': 0.5740089172319741, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7796130905308785, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7796130905308785\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04801286000342183, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04801286000342183\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6031412758081558, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6031412758081558\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.562621305440624e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.562621305440624e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:43:53,671]\u001b[0m Trial 70 finished with value: 0.03718333841308769 and parameters: {'n_estimators': 250, 'num_leaves': 26, 'learning_rate': 0.020936927254998648, 'lambda_l1': 0.04801286000342183, 'lambda_l2': 2.562621305440624e-07, 'feature_fraction': 0.7796130905308785, 'bagging_fraction': 0.6031412758081558, 'bagging_freq': 3, 'min_child_samples': 64}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7526435809356685, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7526435809356685\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.012710789255585858, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.012710789255585858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5705784159946663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5705784159946663\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8009792147201026e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8009792147201026e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:44:02,389]\u001b[0m Trial 71 finished with value: 0.03687990454155991 and parameters: {'n_estimators': 250, 'num_leaves': 25, 'learning_rate': 0.025269591408594597, 'lambda_l1': 0.012710789255585858, 'lambda_l2': 1.8009792147201026e-07, 'feature_fraction': 0.7526435809356685, 'bagging_fraction': 0.5705784159946663, 'bagging_freq': 3, 'min_child_samples': 58}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7915891310729485, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7915891310729485\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.30206400565725583, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.30206400565725583\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5492756575931614, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5492756575931614\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.12305546867593e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.12305546867593e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:44:08,244]\u001b[0m Trial 72 finished with value: 0.036157192954251655 and parameters: {'n_estimators': 250, 'num_leaves': 25, 'learning_rate': 0.03470475399773831, 'lambda_l1': 0.30206400565725583, 'lambda_l2': 5.12305546867593e-07, 'feature_fraction': 0.7915891310729485, 'bagging_fraction': 0.5492756575931614, 'bagging_freq': 2, 'min_child_samples': 63}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7097707362045211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7097707362045211\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.003954627613208279, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003954627613208279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6408400529225255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6408400529225255\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.545115361104498e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.545115361104498e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:44:16,834]\u001b[0m Trial 73 finished with value: 0.03754184425177052 and parameters: {'n_estimators': 250, 'num_leaves': 24, 'learning_rate': 0.028226103610944242, 'lambda_l1': 0.003954627613208279, 'lambda_l2': 7.545115361104498e-08, 'feature_fraction': 0.7097707362045211, 'bagging_fraction': 0.6408400529225255, 'bagging_freq': 3, 'min_child_samples': 71}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7301723436911363, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7301723436911363\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8721211491962994, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8721211491962994\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5215965185262186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5215965185262186\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0756064131470482, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0756064131470482\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:44:20,556]\u001b[0m Trial 74 finished with value: 0.04337169266112779 and parameters: {'n_estimators': 200, 'num_leaves': 23, 'learning_rate': 0.05276280692395619, 'lambda_l1': 0.8721211491962994, 'lambda_l2': 1.0756064131470482, 'feature_fraction': 0.7301723436911363, 'bagging_fraction': 0.5215965185262186, 'bagging_freq': 2, 'min_child_samples': 76}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6973021565643198, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6973021565643198\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.034027550851587145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.034027550851587145\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769863572293223, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769863572293223\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0018219180151944575, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0018219180151944575\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:44:27,814]\u001b[0m Trial 75 finished with value: 0.0349459541086349 and parameters: {'n_estimators': 250, 'num_leaves': 26, 'learning_rate': 0.0319189560048838, 'lambda_l1': 0.034027550851587145, 'lambda_l2': 0.0018219180151944575, 'feature_fraction': 0.6973021565643198, 'bagging_fraction': 0.5769863572293223, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6914315826393121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6914315826393121\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.054624475231140654, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054624475231140654\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5850179413148532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5850179413148532\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0028079713808227616, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0028079713808227616\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:44:33,962]\u001b[0m Trial 76 finished with value: 0.03499286979183678 and parameters: {'n_estimators': 250, 'num_leaves': 28, 'learning_rate': 0.043307418764659704, 'lambda_l1': 0.054624475231140654, 'lambda_l2': 0.0028079713808227616, 'feature_fraction': 0.6914315826393121, 'bagging_fraction': 0.5850179413148532, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6525974961410361, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6525974961410361\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.029735611396670407, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.029735611396670407\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5683313922235157, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5683313922235157\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.780150769189062e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.780150769189062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:44:41,090]\u001b[0m Trial 77 finished with value: 0.03733047519525024 and parameters: {'n_estimators': 250, 'num_leaves': 27, 'learning_rate': 0.030891795815256445, 'lambda_l1': 0.029735611396670407, 'lambda_l2': 7.780150769189062e-07, 'feature_fraction': 0.6525974961410361, 'bagging_fraction': 0.5683313922235157, 'bagging_freq': 3, 'min_child_samples': 54}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7743717322612895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7743717322612895\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.016894112856576878, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.016894112856576878\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6590789224636544, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6590789224636544\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.236711008887465e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.236711008887465e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:44:50,080]\u001b[0m Trial 78 finished with value: 0.03756161822598633 and parameters: {'n_estimators': 250, 'num_leaves': 26, 'learning_rate': 0.02350966129483146, 'lambda_l1': 0.016894112856576878, 'lambda_l2': 6.236711008887465e-06, 'feature_fraction': 0.7743717322612895, 'bagging_fraction': 0.6590789224636544, 'bagging_freq': 2, 'min_child_samples': 70}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.667753434227937, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.667753434227937\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.007130419772125105, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007130419772125105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004471896934508, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004471896934508\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00032819984761369315, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00032819984761369315\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:44:57,842]\u001b[0m Trial 79 finished with value: 0.039515806120805894 and parameters: {'n_estimators': 250, 'num_leaves': 29, 'learning_rate': 0.04027674709912949, 'lambda_l1': 0.007130419772125105, 'lambda_l2': 0.00032819984761369315, 'feature_fraction': 0.667753434227937, 'bagging_fraction': 0.6004471896934508, 'bagging_freq': 3, 'min_child_samples': 50}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7616937143606246, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7616937143606246\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1627085855513243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1627085855513243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6216190435854967, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6216190435854967\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6102316964464484e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6102316964464484e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:45:04,046]\u001b[0m Trial 80 finished with value: 0.035093762755048795 and parameters: {'n_estimators': 250, 'num_leaves': 29, 'learning_rate': 0.03440950160555699, 'lambda_l1': 0.1627085855513243, 'lambda_l2': 1.6102316964464484e-05, 'feature_fraction': 0.7616937143606246, 'bagging_fraction': 0.6216190435854967, 'bagging_freq': 2, 'min_child_samples': 84}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6920040486217378, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6920040486217378\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06616815411043028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06616815411043028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5824405115344935, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5824405115344935\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0024027704815788318, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0024027704815788318\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:45:09,872]\u001b[0m Trial 81 finished with value: 0.03550800452341788 and parameters: {'n_estimators': 250, 'num_leaves': 27, 'learning_rate': 0.04858653664312729, 'lambda_l1': 0.06616815411043028, 'lambda_l2': 0.0024027704815788318, 'feature_fraction': 0.6920040486217378, 'bagging_fraction': 0.5824405115344935, 'bagging_freq': 2, 'min_child_samples': 56}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7009964379697546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7009964379697546\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0387600386957657, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0387600386957657\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5432332001777647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5432332001777647\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.013044447194833109, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.013044447194833109\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:45:15,952]\u001b[0m Trial 82 finished with value: 0.03511497160371641 and parameters: {'n_estimators': 250, 'num_leaves': 28, 'learning_rate': 0.04341631646789174, 'lambda_l1': 0.0387600386957657, 'lambda_l2': 0.013044447194833109, 'feature_fraction': 0.7009964379697546, 'bagging_fraction': 0.5432332001777647, 'bagging_freq': 2, 'min_child_samples': 66}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6344383004565189, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6344383004565189\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3817621996021902, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3817621996021902\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.639742293465736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.639742293465736\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0010774940669280946, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0010774940669280946\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:45:20,293]\u001b[0m Trial 83 finished with value: 0.035966046919327074 and parameters: {'n_estimators': 250, 'num_leaves': 30, 'learning_rate': 0.05463497580663219, 'lambda_l1': 0.3817621996021902, 'lambda_l2': 0.0010774940669280946, 'feature_fraction': 0.6344383004565189, 'bagging_fraction': 0.639742293465736, 'bagging_freq': 2, 'min_child_samples': 58}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7251834685594043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7251834685594043\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08023157664520744, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08023157664520744\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5934494858843319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5934494858843319\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8629605160898394e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8629605160898394e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:45:27,344]\u001b[0m Trial 84 finished with value: 0.03439548378349443 and parameters: {'n_estimators': 250, 'num_leaves': 25, 'learning_rate': 0.031474158191395964, 'lambda_l1': 0.08023157664520744, 'lambda_l2': 2.8629605160898394e-08, 'feature_fraction': 0.7251834685594043, 'bagging_fraction': 0.5934494858843319, 'bagging_freq': 2, 'min_child_samples': 50}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7205906320643181, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7205906320643181\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09114221653941429, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09114221653941429\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6136458271406671, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6136458271406671\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7850469886819268e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7850469886819268e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:45:35,078]\u001b[0m Trial 85 finished with value: 0.035967201464184646 and parameters: {'n_estimators': 250, 'num_leaves': 25, 'learning_rate': 0.02644759463687951, 'lambda_l1': 0.09114221653941429, 'lambda_l2': 2.7850469886819268e-08, 'feature_fraction': 0.7205906320643181, 'bagging_fraction': 0.6136458271406671, 'bagging_freq': 2, 'min_child_samples': 38}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.740852051701202, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.740852051701202\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3859596345790494, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3859596345790494\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7138888344662446, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138888344662446\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.5504267980309186e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.5504267980309186e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:45:39,653]\u001b[0m Trial 86 finished with value: 0.04310222320591446 and parameters: {'n_estimators': 150, 'num_leaves': 24, 'learning_rate': 0.031198229443348657, 'lambda_l1': 0.3859596345790494, 'lambda_l2': 1.5504267980309186e-07, 'feature_fraction': 0.740852051701202, 'bagging_fraction': 0.7138888344662446, 'bagging_freq': 3, 'min_child_samples': 50}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7883784603843382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7883784603843382\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.007610985308181804, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007610985308181804\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46701755154746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46701755154746\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.881513891109981e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.881513891109981e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:45:48,282]\u001b[0m Trial 87 finished with value: 0.03817302022567446 and parameters: {'n_estimators': 250, 'num_leaves': 23, 'learning_rate': 0.022599807176178415, 'lambda_l1': 0.007610985308181804, 'lambda_l2': 2.881513891109981e-07, 'feature_fraction': 0.7883784603843382, 'bagging_fraction': 0.46701755154746, 'bagging_freq': 2, 'min_child_samples': 47}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8139885347390415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8139885347390415\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22607292774527793, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22607292774527793\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5976973969162925, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5976973969162925\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6709828812535915e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6709828812535915e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:45:55,584]\u001b[0m Trial 88 finished with value: 0.04828424646820256 and parameters: {'n_estimators': 250, 'num_leaves': 20, 'learning_rate': 0.015596238933119217, 'lambda_l1': 0.22607292774527793, 'lambda_l2': 1.6709828812535915e-06, 'feature_fraction': 0.8139885347390415, 'bagging_fraction': 0.5976973969162925, 'bagging_freq': 4, 'min_child_samples': 73}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7525680527300782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7525680527300782\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02559876190473874, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02559876190473874\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5303539824619523, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5303539824619523\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.929157838301223e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.929157838301223e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:46:00,377]\u001b[0m Trial 89 finished with value: 0.03918775435703551 and parameters: {'n_estimators': 250, 'num_leaves': 26, 'learning_rate': 0.08055012224616499, 'lambda_l1': 0.02559876190473874, 'lambda_l2': 7.929157838301223e-08, 'feature_fraction': 0.7525680527300782, 'bagging_fraction': 0.5303539824619523, 'bagging_freq': 3, 'min_child_samples': 79}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8535065580749199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8535065580749199\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0025525471369757017, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0025525471369757017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5559303640477165, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5559303640477165\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.573483438317234e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.573483438317234e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:46:04,503]\u001b[0m Trial 90 finished with value: 0.04850330408388253 and parameters: {'n_estimators': 100, 'num_leaves': 22, 'learning_rate': 0.03697696928229546, 'lambda_l1': 0.0025525471369757017, 'lambda_l2': 3.573483438317234e-07, 'feature_fraction': 0.8535065580749199, 'bagging_fraction': 0.5559303640477165, 'bagging_freq': 2, 'min_child_samples': 62}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6840761434104399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6840761434104399\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07105140978791834, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07105140978791834\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5739569889553156, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5739569889553156\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007637082723624125, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007637082723624125\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:46:09,231]\u001b[0m Trial 91 finished with value: 0.035053540896349794 and parameters: {'n_estimators': 250, 'num_leaves': 25, 'learning_rate': 0.06791372253046532, 'lambda_l1': 0.07105140978791834, 'lambda_l2': 0.007637082723624125, 'feature_fraction': 0.6840761434104399, 'bagging_fraction': 0.5739569889553156, 'bagging_freq': 2, 'min_child_samples': 58}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7251268788284871, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7251268788284871\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13629538015531673, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13629538015531673\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.588050243757394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.588050243757394\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0023977935277042475, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0023977935277042475\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:46:14,886]\u001b[0m Trial 92 finished with value: 0.033482646014228026 and parameters: {'n_estimators': 250, 'num_leaves': 28, 'learning_rate': 0.04667426637681484, 'lambda_l1': 0.13629538015531673, 'lambda_l2': 0.0023977935277042475, 'feature_fraction': 0.7251268788284871, 'bagging_fraction': 0.588050243757394, 'bagging_freq': 2, 'min_child_samples': 52}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7983063283641536, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7983063283641536\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1416116220223503, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1416116220223503\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6108905758308317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6108905758308317\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005227554112069585, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005227554112069585\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:46:21,398]\u001b[0m Trial 93 finished with value: 0.035572756611373255 and parameters: {'n_estimators': 250, 'num_leaves': 24, 'learning_rate': 0.031506119050428154, 'lambda_l1': 0.1416116220223503, 'lambda_l2': 0.005227554112069585, 'feature_fraction': 0.7983063283641536, 'bagging_fraction': 0.6108905758308317, 'bagging_freq': 2, 'min_child_samples': 87}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7254187853248705, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7254187853248705\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1380103223138005, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1380103223138005\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4859182355577381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4859182355577381\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0013682438433685704, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013682438433685704\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:46:25,772]\u001b[0m Trial 94 finished with value: 0.04155390825275376 and parameters: {'n_estimators': 250, 'num_leaves': 25, 'learning_rate': 0.03953544510504405, 'lambda_l1': 1.1380103223138005, 'lambda_l2': 0.0013682438433685704, 'feature_fraction': 0.7254187853248705, 'bagging_fraction': 0.4859182355577381, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7753965928773203, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7753965928773203\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10873295487850293, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10873295487850293\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5916231276800901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5916231276800901\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.478180764005217e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.478180764005217e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:46:31,739]\u001b[0m Trial 95 finished with value: 0.03434684058972724 and parameters: {'n_estimators': 250, 'num_leaves': 27, 'learning_rate': 0.04753792266629984, 'lambda_l1': 0.10873295487850293, 'lambda_l2': 3.478180764005217e-08, 'feature_fraction': 0.7753965928773203, 'bagging_fraction': 0.5916231276800901, 'bagging_freq': 1, 'min_child_samples': 48}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7114819447816052, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7114819447816052\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11173878690069566, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11173878690069566\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6851086845930376, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6851086845930376\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7774695716101212e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7774695716101212e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:46:37,645]\u001b[0m Trial 96 finished with value: 0.03570697304711363 and parameters: {'n_estimators': 250, 'num_leaves': 32, 'learning_rate': 0.047852189678516475, 'lambda_l1': 0.11173878690069566, 'lambda_l2': 1.7774695716101212e-08, 'feature_fraction': 0.7114819447816052, 'bagging_fraction': 0.6851086845930376, 'bagging_freq': 1, 'min_child_samples': 45}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7380255497596238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7380255497596238\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.25805755589274426, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.25805755589274426\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5107659235382417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5107659235382417\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.329711206153987e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.329711206153987e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:46:42,033]\u001b[0m Trial 97 finished with value: 0.03623055990845488 and parameters: {'n_estimators': 250, 'num_leaves': 27, 'learning_rate': 0.06073830436812624, 'lambda_l1': 0.25805755589274426, 'lambda_l2': 3.329711206153987e-08, 'feature_fraction': 0.7380255497596238, 'bagging_fraction': 0.5107659235382417, 'bagging_freq': 1, 'min_child_samples': 51}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7659294102857968, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7659294102857968\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.562184829670046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.562184829670046\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.632269599130739, subsample=1.0 will be ignored. Current value: bagging_fraction=0.632269599130739\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01963916747530243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01963916747530243\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:46:46,849]\u001b[0m Trial 98 finished with value: 0.0364603045837925 and parameters: {'n_estimators': 250, 'num_leaves': 28, 'learning_rate': 0.05061254167919268, 'lambda_l1': 0.562184829670046, 'lambda_l2': 0.01963916747530243, 'feature_fraction': 0.7659294102857968, 'bagging_fraction': 0.632269599130739, 'bagging_freq': 1, 'min_child_samples': 52}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n",
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\optuna\\trial\\_trial.py:777: RuntimeWarning:\n",
      "\n",
      "Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 15, 'high': 40, 'step': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8360088121298638, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8360088121298638\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.015476230502801655, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015476230502801655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6560871629952527, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6560871629952527\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0008229682538936538, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008229682538936538\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-14 16:46:52,633]\u001b[0m Trial 99 finished with value: 0.0398431436271541 and parameters: {'n_estimators': 250, 'num_leaves': 22, 'learning_rate': 0.07913966026398965, 'lambda_l1': 0.015476230502801655, 'lambda_l2': 0.0008229682538936538, 'feature_fraction': 0.8360088121298638, 'bagging_fraction': 0.6560871629952527, 'bagging_freq': 1, 'min_child_samples': 48}. Best is trial 68 with value: 0.03337641067842687.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    est = [100, 150, 200, 250]\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', est),\n",
    "        'num_leaves' : trial.suggest_int('num_leaves', 15, 40),\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.8),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "            }\n",
    "    clf = LGBMClassifier(**param)\n",
    "    clf.fit(x_train, y_train)\n",
    "    return log_loss(y_val, clf.predict_proba(x_val.reset_index().drop('index', axis = 1)))\n",
    "\n",
    "import optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "rotary-switch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 250,\n",
       " 'num_leaves': 25,\n",
       " 'learning_rate': 0.03273819078795996,\n",
       " 'lambda_l1': 0.06347385911744392,\n",
       " 'lambda_l2': 2.494311773332968e-07,\n",
       " 'feature_fraction': 0.7775729945527079,\n",
       " 'bagging_fraction': 0.6031044675911276,\n",
       " 'bagging_freq': 2,\n",
       " 'min_child_samples': 71}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = study.best_params\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "verbal-genome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7775729945527079, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7775729945527079\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06347385911744392, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06347385911744392\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6031044675911276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6031044675911276\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.494311773332968e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.494311773332968e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Train error for LightGBM Classifier is  0.0009980754859986658\n",
      "Cross Validation error for LightGBM Classifier is  0.03337641067842687\n",
      "Train error for LightGBM Classifier with calliberation is  0.0011844274360488431\n",
      "Cross Validation error for LightGBM Classifier with calliberation is  0.06601329255827793\n"
     ]
    }
   ],
   "source": [
    "# LightGBM model\n",
    "clf = LGBMClassifier(n_estimators = 250,\n",
    " num_leaves = 25,\n",
    " learning_rate = 0.03273819078795996,\n",
    " lambda_l1 = 0.06347385911744392,\n",
    " lambda_l2 = 2.494311773332968e-07,\n",
    " feature_fraction = 0.7775729945527079,\n",
    " bagging_fraction = 0.6031044675911276,\n",
    " bagging_freq = 2,\n",
    " min_child_samples = 71)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# calliberartion model\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv = 'prefit' )\n",
    "sig_clf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# find log loss error\n",
    "loss = log_loss(y_val, clf.predict_proba(x_val))\n",
    "loss_c = log_loss(y_val, sig_clf.predict_proba(x_val))\n",
    "\n",
    "print('Train error for LightGBM Classifier is ', log_loss(y_train, clf.predict_proba(x_train)))\n",
    "print('Cross Validation error for LightGBM Classifier is ',loss)\n",
    "\n",
    "print('Train error for LightGBM Classifier with calliberation is ', log_loss(y_train, sig_clf.predict_proba(x_train)))\n",
    "print('Cross Validation error for LightGBM Classifier with calliberation is ',loss_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "wireless-addiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning:\n",
      "\n",
      "Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3200x3200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(x_val)\n",
    "c = confusion_matrix(y_pred, y_val)\n",
    "\n",
    "plt.figure(figsize = (40, 40), )\n",
    "plot_confusion_matrix(clf, x_val, y_val, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-requirement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
